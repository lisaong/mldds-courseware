{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition\n",
    "\n",
    "A survey of statistical and deep learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Automatic Speech Recognition Pipeline\n",
    "\n",
    "<img src='assets/speech/asr-pipeline.jpg'/>\n",
    "\n",
    "\n",
    "Source: https://www.techrepublic.com/article/how-we-learned-to-talk-to-computers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Speech Feature Extraction\n",
    "\n",
    "<img src='assets/speech/Spectrogram-19thC.png'/>\n",
    "\n",
    "A spectrogram for \"nineteen century\" - power vs. frequency\n",
    "\n",
    "Common method: Mel-frequency cepstral coefficients (MFCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical Speech Recognition\n",
    "\n",
    "$$W^* = \\underset{W}{\\operatorname{argmax}}P(W|X)$$\n",
    "\n",
    "- word sequence: $W$\n",
    "- most likely word sequence: $W^*$\n",
    "- acoustic input feature vector (e.g. MFCC): $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical Speech Recognition\n",
    "\n",
    "After Bayes' Theorem:\n",
    "\n",
    "$$W^* = \\underset{W}{\\operatorname{argmax}}p(X|W)P(W)$$\n",
    "\n",
    "- acoustic model: $p(X|W)$\n",
    "- language model (e.g. N-gram): $P(W)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical Acoustic Model: $p(X|W)$\n",
    "\n",
    "<img src='assets/speech/acoustic-statistical.png' width='50%'/>\n",
    "\n",
    "Credits: https://www.inf.ed.ac.uk/teaching/courses/asr/2016-17/asr03-hmmgmm-handout.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hidden Markov Model: $p(S_i|S_{i-1})$, Gaussian Mixture Model: $p(X|S_i)$\n",
    "\n",
    "<img src='assets/speech/acoustic-hmm-gmm.png' width='50%'/>\n",
    "\n",
    "Credits: https://www.inf.ed.ac.uk/teaching/courses/asr/2016-17/asr03-hmmgmm-handout.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Model\n",
    "\n",
    "Mixture distribution: combine multiple probabability distributions to make an improved model\n",
    "\n",
    "$$P(x) = \\sum_iP(c=i)P(x \\mid c=i)$$\n",
    "\n",
    "$i^{th}$ Gaussian component: $P(x \\mid c=i)$\n",
    "\n",
    "Applications\n",
    "- Clustering\n",
    "- Classification\n",
    "\n",
    "Nice intro:\n",
    "https://yulearning.blogspot.sg/2014/11/einsteins-most-famous-equation-is-emc2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workshop: GMM gender detector\n",
    "---\n",
    "\n",
    "Credits: https://github.com/abhijeet3922/PyGender-Voice\n",
    "\n",
    "<img src='assets/speech/workshop1_pygender.png' style='float:right'/>\n",
    "\n",
    "1. Download data from [here](\n",
    "https://www.dropbox.com/s/hcku4t7alrhacqv/pygender.zip?dl=0)\n",
    "\n",
    "2. Extract the .zip file to a folder of your choice. Note down the path as you will need to enter it in the workshop code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# !pip3 install python_speech_features\n",
    "\n",
    "import os\n",
    "from os.path import basename, join\n",
    "import numpy as np\n",
    "\n",
    "from python_speech_features import mfcc\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn import preprocessing\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "TRAIN_PATH = 'C:\\\\mldds\\\\pygender\\\\train_data\\\\youtube\\\\' # modify to your actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def get_MFCC(audio_file, scale=True):\n",
    "    \"\"\"Computes the Mel-frequency ceptrum coefficients for an audio file\n",
    "    Args:\n",
    "        audio_file: input audio file\n",
    "        scale: whether to scale the features between 0-1\n",
    "    Returns:\n",
    "        the MFCC features\n",
    "    \"\"\"    \n",
    "    sample_rate, audio = read(audio_file)\n",
    "    features = mfcc(audio, sample_rate, winlen=0.025, winstep=0.01,\n",
    "                    numcep=13, appendEnergy=False)\n",
    "    if scale:\n",
    "        features = preprocessing.scale(features) # scale to (0, 1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Playback a sample file\n",
    "from IPython import display\n",
    "\n",
    "sample_file = join(TRAIN_PATH, 'male', 'male1.wav')\n",
    "sample_rate, audio = read(sample_file)\n",
    "display.Audio(data=audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the MFCC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mfcc_vector = get_MFCC(sample_file, scale=False)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20,4))\n",
    "cax = ax.matshow(np.transpose(mfcc_vector), interpolation='nearest',\n",
    "                 aspect='auto', cmap='coolwarm', origin='lower')\n",
    "fig.colorbar(cax)\n",
    "plt.title(\"Spectrogram of {}\".format(sample_file))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def train_GMM(data_path, n_components=8, covariance_type='diag'):\n",
    "    \"\"\"Trains a Gaussian mixture model\n",
    "    Args:\n",
    "        data_path: data folder path\n",
    "        n_components: number of Gaussian components\n",
    "        covariance_type: type of covariance matrix\n",
    "    Returns:\n",
    "        the GMM model\n",
    "    \"\"\"    \n",
    "    files = [join(data_path, f) for f in os.listdir(data_path) if f.endswith('.wav')]\n",
    "    features = np.asarray(());\n",
    "\n",
    "    for f in files:\n",
    "        mfcc_vector = get_MFCC(f)\n",
    "\n",
    "        if features.size:\n",
    "            features = np.vstack((features, mfcc_vector))\n",
    "        else:\n",
    "            features = mfcc_vector\n",
    "\n",
    "    gmm = GaussianMixture(n_components=n_components,\n",
    "                          covariance_type=covariance_type,\n",
    "                          max_iter=200, n_init=3)\n",
    "    gmm.fit(features)\n",
    "    \n",
    "    # print some metrics applicable to GMMs\n",
    "    print('BIC: ', gmm.bic(features), ', AIC: ', gmm.aic(features))\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "models = dict()\n",
    "%time models['male'] = train_GMM(join(TRAIN_PATH, 'male'), n_components=8, \\\n",
    "                                 covariance_type='diag')\n",
    "\n",
    "# ==================================================================\n",
    "# Exercise:\n",
    "# Add code below to train the female model, using the above as an example\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==================================================================\n",
    "# Optional Exercises:\n",
    "# a. Try different values of n_component (e.g. 2, 16)\n",
    "# b. Try different values of covariance_type (e.g. full)\n",
    "#\n",
    "# See http://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html\n",
    "# on how to interpret the BIC and AIC metrics for selecting models\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def test_GMM(models, test_data_path):\n",
    "    \"\"\"Trains a Gaussian mixture model\n",
    "    Args:\n",
    "        models: {name: gmm} dictionary of models\n",
    "        test_data_path: test data folder path\n",
    "    Returns:\n",
    "        the predictions\n",
    "    \"\"\"    \n",
    "    files = [os.path.join(test_data_path,f) for f in os.listdir(test_data_path)\n",
    "             if f.endswith(\".wav\")]\n",
    "    \n",
    "    predictions = []\n",
    "    for f in files:\n",
    "        features = get_MFCC(f)\n",
    "        keys = []\n",
    "        log_likelihood = np.zeros(len(models))\n",
    "\n",
    "        for i, (key, gmm) in enumerate(models.items()):\n",
    "            scores = np.array(gmm.score(features))\n",
    "            keys.append(key)\n",
    "            log_likelihood[i] = scores.sum()\n",
    "\n",
    "        # find the model with the maximum score\n",
    "        winner = np.argmax(log_likelihood)\n",
    "        # print('prediction:', keys[winner], \"\\tscores:\", log_likelihood[winner])\n",
    "        predictions.append(keys[winner])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# ==================================================================\n",
    "# Exercise:\n",
    "# 1. Complete the code below to test the GMM models using test_GMM().\n",
    "#    Be sure to run against both male and female models.\n",
    "# 2. Plot the confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "TEST_PATH = 'C:\\\\mldds\\\\pygender\\\\test_data\\\\AudioSet' # modify to your actual path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Shortcomings of Statistical Approaches\n",
    "\n",
    "Lots of hand-tuning\n",
    "\n",
    "Inefficient for approximating non-linear data: combination covariance matrices get very large / complicated\n",
    "\n",
    "Solution: deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep Belief Nets\n",
    "\n",
    "[Paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38131.pdf)\n",
    "\n",
    "- Replaces the Gaussian Mixture Model in an ASR system \n",
    "- Generative pre-training\n",
    " - Speeds up training with less overfitting\n",
    " - Train a hidden layer (using Restricted Boltmann Machines or Gaussian RBM)\n",
    " - Use the weights as inputs to train next layer\n",
    " - Stack up into a forward-only \"Deep Belief Net\" (DBN)\n",
    " - Add softmax to create the DBM-DNN\n",
    "\n",
    "Python: https://pypi.org/project/nolearn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![DBN-DNN](assets/speech/dbn-dnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![DBN-DNN performance](assets/speech/dbn-dnn-compare.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word Error Rate\n",
    "\n",
    "$$WER = \\frac{S + D + I}{N}$$\n",
    "\n",
    "- substitution word count: $S$\n",
    "- deletion word count: $D$\n",
    "- insertion word count: $I$\n",
    "- correct word count: $C$\n",
    "- number of reference words: $N = S + D + C$\n",
    "\n",
    "## Word Accuracy\n",
    "$$WAcc = 1 - WER = \\frac{(N - S - D) - I}{N} = \\frac{C - I}{N} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recurrent Neural Networks\n",
    "\n",
    "[Paper](http://proceedings.mlr.press/v32/graves14.pdf)\n",
    "\n",
    "End-to-End Speech Recognition\n",
    "- Transcription is hard. Skip it and train model that converts speech directly to text\n",
    "- Bidirectional LSTM to learn long sequences\n",
    "- Correctionist Temporal Classification (CTC) to align audio with text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LSTM\n",
    "\n",
    "- Learns long sequences (like speech)\n",
    "- Forget gate learns what to forget\n",
    "\n",
    "![lstm](assets/speech/lstm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Birectional RNN\n",
    "\n",
    "- Forward ($\\overrightarrow{h}$) and backward ($\\overleftarrow{h}$) hidden sequences\n",
    "- Learns context in both directions (like words in speech)\n",
    "- Bidirectional LSTM: LSTM hidden units \n",
    "\n",
    "![BRNN](assets/speech/brnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Correctionist Temporal Classification\n",
    "\n",
    "[Paper](https://www.cs.toronto.edu/~graves/icml_2006.pdf)\n",
    "\n",
    "- To train speech to text, we need to know how audio \"lines up\" with transcripts\n",
    "- Input sequences: $X$ (such as audio)\n",
    "- Output sequences: $Y$ (such as transcripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Correctionist Temporal Classification\n",
    "\n",
    "Problem: $X$ and $Y$ can vary in length, in different ways\n",
    "![CTC](assets/speech/naive_alignment.svg)\n",
    "\n",
    "Solution: introduce the blank token ($\\epsilon$)\n",
    "![CTC](assets/speech/ctc_alignment_steps.svg)\n",
    "\n",
    "Process: train an RNN to estimate probabilities of each character per time step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Correctionist Temporal Classification\n",
    "\n",
    "![CTC](assets/speech/full_collapse_from_audio.svg)\n",
    "\n",
    "[Visual Guide and Explanation](https://distill.pub/2017/ctc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Walkthrough: CTC\n",
    "---\n",
    "Credits: https://github.com/igormq/ctc_tensorflow_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/lspvic/jupyter_tensorboard\n",
    "# !pip3 install jupyter-tensorboard\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from python_speech_features import mfcc\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "SPACE_TOKEN = '<space>'\n",
    "SPACE_INDEX = 0\n",
    "FIRST_INDEX = ord('a') - 1  # 0 is reserved to space\n",
    "\n",
    "# Configuration\n",
    "num_features = 13\n",
    "num_units = 50 # Number of units in the LSTM cell\n",
    "\n",
    "# Number of classes: 'a' to 'z' +  space + blank label = 28 characters\n",
    "num_classes = ord('z') - ord('a') + 1 + 1 + 1\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 200\n",
    "num_hidden = 50\n",
    "num_layers = 1\n",
    "batch_size = 1\n",
    "initial_learning_rate = 1e-2\n",
    "momentum = 0.9\n",
    "\n",
    "num_examples = 1\n",
    "num_batches_per_epoch = int(num_examples/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def process_audio(audio_file):\n",
    "    \"\"\"Extracts the MFCC features from an audio file.\n",
    "    Args:\n",
    "        audio_file: file containing the input audio\n",
    "    Returns:\n",
    "        A tuple with (features, sequence length)\n",
    "    \"\"\"\n",
    "    sample_rate, audio = read(audio_file)\n",
    "    features = mfcc(audio, sample_rate)\n",
    "    features = preprocessing.scale(features) # scale to (0, 1)\n",
    "\n",
    "    features = np.asarray(features[np.newaxis, :])\n",
    "    features_seq_len = [features.shape[1]]\n",
    "    return features, features_seq_len\n",
    "\n",
    "# Process audio\n",
    "TRAIN_INPUT = join('files', 'CTC', 'LDC93S1.wav')\n",
    "train_input, train_seq_len = process_audio(TRAIN_INPUT)\n",
    "\n",
    "VAL_INPUT = join('files', 'CTC', '61-70968-0002.wav')\n",
    "val_input, val_seq_len = process_audio(VAL_INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: your dark suit in greasy wash water all year\n",
      "Targets: [25 15 21 18  0  4  1 18 11  0 19 21  9 20  0  9 14  0  7 18  5  1 19 25\n",
      "  0 23  1 19  8  0 23  1 20  5 18  0  1 12 12  0 25  5  1 18]\n",
      "Original text: fortune and a happy life\n",
      "Targets: [ 6 15 18 20 21 14  5  0  1 14  4  0  1  0  8  1 16 16 25  0 12  9  6  5]\n"
     ]
    }
   ],
   "source": [
    "def sparse_tuple_from(sequences, dtype=np.int32):\n",
    "    \"\"\"Create a sparse representation of sequences.\n",
    "    Args:\n",
    "        sequences: a list of lists of type dtype where each element is a sequence\n",
    "    Returns:\n",
    "        A tuple with (indices, values, shape)\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    for n, seq in enumerate(sequences):\n",
    "        indices.extend(zip([n]*len(seq), range(len(seq))))\n",
    "        values.extend(seq)\n",
    "\n",
    "    indices = np.asarray(indices, dtype=np.int64)\n",
    "    values = np.asarray(values, dtype=dtype)\n",
    "    shape = np.asarray([len(sequences), np.asarray(indices).max(0)[1]+1], dtype=np.int64)\n",
    "\n",
    "    return indices, values, shape\n",
    "\n",
    "def process_targets(text_file):\n",
    "    \"\"\"Extracts the CTC tokens from an input text file.\n",
    "    Args:\n",
    "        text_file: file containing the input text\n",
    "    Returns:\n",
    "        A nested tuple with (original text, (indices, CTC tokens, shape))\n",
    "    \"\"\"\n",
    "    with open(text_file, 'r') as f:\n",
    "        line = f.readlines()[-1] # take the last line\n",
    "\n",
    "        # Get only the words between [a-z], replace period for none\n",
    "        original = ' '.join(line.strip().lower().split(' ')).replace('.', '')\n",
    "        targets = original.replace(' ', '  ')\n",
    "        targets = targets.split(' ')\n",
    "\n",
    "    # Add blank label\n",
    "    targets = np.hstack([SPACE_TOKEN if x == '' else list(x) for x in targets])\n",
    "\n",
    "    # Transform char into index\n",
    "    targets = np.asarray([SPACE_INDEX if x == SPACE_TOKEN else ord(x) - FIRST_INDEX\n",
    "                          for x in targets])\n",
    "\n",
    "    # Creat sparse representation to feed into the graph\n",
    "    return original, sparse_tuple_from([targets])\n",
    "\n",
    "# Process transcription\n",
    "TRAIN_TARGET = join('files', 'CTC', 'LDC93S1.txt')\n",
    "train_original, train_targets = process_targets(TRAIN_TARGET)\n",
    "print(\"Original text:\", train_original)\n",
    "print(\"Targets:\", train_targets[1])\n",
    "\n",
    "VAL_TARGET = join('files', 'CTC', '61-70968-0002.txt')\n",
    "val_original, val_targets = process_targets(VAL_TARGET)\n",
    "print(\"Original text:\", val_original)\n",
    "print(\"Targets:\", val_targets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # e.g: log filter bank or MFCC features\n",
    "    # Has size [batch_size, max_stepsize, num_features], but the\n",
    "    # batch_size and max_stepsize can vary along each step\n",
    "    inputs = tf.placeholder(tf.float32, [None, None, num_features])\n",
    "\n",
    "    # Here we use sparse_placeholder that will generate a\n",
    "    # SparseTensor required by ctc_loss op.\n",
    "    targets = tf.sparse_placeholder(tf.int32)\n",
    "\n",
    "    # 1d array of size [batch_size]\n",
    "    seq_len = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "    # Defining the cell\n",
    "    # Can be:\n",
    "    #   tf.nn.rnn_cell.RNNCell\n",
    "    #   tf.nn.rnn_cell.GRUCell \n",
    "    cells = []\n",
    "    for _ in range(num_layers):\n",
    "        cell = tf.contrib.rnn.LSTMCell(num_units)\n",
    "        cells.append(cell)\n",
    "    stack = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "\n",
    "    # The second output is the last state and we will no use that\n",
    "    outputs, _ = tf.nn.dynamic_rnn(stack, inputs, seq_len, dtype=tf.float32)\n",
    "\n",
    "    shape = tf.shape(inputs)\n",
    "    batch_s, max_timesteps = shape[0], shape[1]\n",
    "\n",
    "    # Reshaping to apply the same weights over the timesteps\n",
    "    outputs = tf.reshape(outputs, [-1, num_hidden])\n",
    "\n",
    "    # Truncated normal with mean 0 and stdev=0.1\n",
    "    W = tf.Variable(tf.truncated_normal([num_hidden,\n",
    "                                         num_classes],\n",
    "                                        stddev=0.1))\n",
    "    # Zero initialization\n",
    "    b = tf.Variable(tf.constant(0., shape=[num_classes]))\n",
    "\n",
    "    # Doing the affine projection\n",
    "    logits = tf.matmul(outputs, W) + b\n",
    "\n",
    "    # Reshaping back to the original shape\n",
    "    logits = tf.reshape(logits, [batch_s, -1, num_classes])\n",
    "\n",
    "    # Time major\n",
    "    logits = tf.transpose(logits, (1, 0, 2))\n",
    "\n",
    "    loss = tf.nn.ctc_loss(targets, logits, seq_len)\n",
    "    cost = tf.reduce_mean(loss)\n",
    "\n",
    "    optimizer = tf.train.MomentumOptimizer(initial_learning_rate,\n",
    "                                           0.9).minimize(cost)\n",
    "\n",
    "    # Option 2: tf.nn.ctc_beam_search_decoder\n",
    "    # (it's slower but you'll get better results)\n",
    "    decoded, log_prob = tf.nn.ctc_greedy_decoder(logits, seq_len)\n",
    "\n",
    "    # Inaccuracy: label error rate\n",
    "    ler = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32),\n",
    "                                          targets))\n",
    "    \n",
    "    # TensorBoard summary operation\n",
    "    tf.summary.scalar('ctc_cost', cost)\n",
    "    tf.summary.scalar('label_error_rate', ler)\n",
    "    summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, train_cost = 774.809, train_ler = 1.000, val_cost = 1115.457, val_ler = 1.000, time = 0.225\n",
      "Epoch 2/200, train_cost = 497.494, train_ler = 1.000, val_cost = 96.116, val_ler = 1.000, time = 0.096\n",
      "Epoch 3/200, train_cost = 218.598, train_ler = 1.000, val_cost = 129.305, val_ler = 1.000, time = 0.094\n",
      "Epoch 4/200, train_cost = 253.486, train_ler = 1.000, val_cost = 127.988, val_ler = 1.000, time = 0.120\n",
      "Epoch 5/200, train_cost = 144.481, train_ler = 0.886, val_cost = 452.867, val_ler = 0.958, time = 0.102\n",
      "Epoch 6/200, train_cost = 156.072, train_ler = 0.886, val_cost = 387.177, val_ler = 0.958, time = 0.105\n",
      "Epoch 7/200, train_cost = 131.799, train_ler = 1.000, val_cost = 130.367, val_ler = 1.000, time = 0.112\n",
      "Epoch 8/200, train_cost = 143.932, train_ler = 0.909, val_cost = 245.622, val_ler = 0.833, time = 0.121\n",
      "Epoch 9/200, train_cost = 130.099, train_ler = 0.864, val_cost = 296.762, val_ler = 0.708, time = 0.122\n",
      "Epoch 10/200, train_cost = 132.673, train_ler = 0.818, val_cost = 356.009, val_ler = 1.000, time = 0.107\n",
      "Epoch 11/200, train_cost = 121.935, train_ler = 0.795, val_cost = 351.628, val_ler = 0.833, time = 0.134\n",
      "Epoch 12/200, train_cost = 114.003, train_ler = 0.886, val_cost = 302.682, val_ler = 0.917, time = 0.113\n",
      "Epoch 13/200, train_cost = 117.319, train_ler = 0.886, val_cost = 307.766, val_ler = 0.875, time = 0.120\n",
      "Epoch 14/200, train_cost = 114.353, train_ler = 0.773, val_cost = 352.424, val_ler = 0.750, time = 0.127\n",
      "Epoch 15/200, train_cost = 110.883, train_ler = 0.864, val_cost = 326.381, val_ler = 0.792, time = 0.129\n",
      "Epoch 16/200, train_cost = 106.179, train_ler = 0.841, val_cost = 264.464, val_ler = 0.792, time = 0.124\n",
      "Epoch 17/200, train_cost = 102.478, train_ler = 0.750, val_cost = 244.842, val_ler = 0.792, time = 0.114\n",
      "Epoch 18/200, train_cost = 100.577, train_ler = 0.773, val_cost = 264.421, val_ler = 0.792, time = 0.107\n",
      "Epoch 19/200, train_cost = 99.196, train_ler = 0.795, val_cost = 288.614, val_ler = 0.958, time = 0.116\n",
      "Epoch 20/200, train_cost = 95.693, train_ler = 0.773, val_cost = 302.413, val_ler = 0.917, time = 0.115\n",
      "Epoch 21/200, train_cost = 91.055, train_ler = 0.750, val_cost = 314.517, val_ler = 0.833, time = 0.111\n",
      "Epoch 22/200, train_cost = 87.697, train_ler = 0.705, val_cost = 307.139, val_ler = 0.792, time = 0.118\n",
      "Epoch 23/200, train_cost = 85.354, train_ler = 0.682, val_cost = 282.461, val_ler = 0.708, time = 0.119\n",
      "Epoch 24/200, train_cost = 82.959, train_ler = 0.727, val_cost = 257.098, val_ler = 0.750, time = 0.129\n",
      "Epoch 25/200, train_cost = 78.967, train_ler = 0.659, val_cost = 241.440, val_ler = 0.750, time = 0.129\n",
      "Epoch 26/200, train_cost = 76.537, train_ler = 0.636, val_cost = 240.730, val_ler = 0.708, time = 0.123\n",
      "Epoch 27/200, train_cost = 72.079, train_ler = 0.500, val_cost = 246.755, val_ler = 0.708, time = 0.120\n",
      "Epoch 28/200, train_cost = 70.146, train_ler = 0.614, val_cost = 258.854, val_ler = 0.708, time = 0.116\n",
      "Epoch 29/200, train_cost = 67.517, train_ler = 0.568, val_cost = 261.599, val_ler = 0.750, time = 0.123\n",
      "Epoch 30/200, train_cost = 64.306, train_ler = 0.568, val_cost = 260.800, val_ler = 0.792, time = 0.127\n",
      "Epoch 31/200, train_cost = 61.366, train_ler = 0.523, val_cost = 267.149, val_ler = 0.792, time = 0.111\n",
      "Epoch 32/200, train_cost = 60.084, train_ler = 0.591, val_cost = 253.595, val_ler = 0.792, time = 0.104\n",
      "Epoch 33/200, train_cost = 56.663, train_ler = 0.568, val_cost = 256.024, val_ler = 0.750, time = 0.108\n",
      "Epoch 34/200, train_cost = 54.425, train_ler = 0.432, val_cost = 259.947, val_ler = 0.792, time = 0.119\n",
      "Epoch 35/200, train_cost = 52.265, train_ler = 0.409, val_cost = 260.480, val_ler = 0.792, time = 0.105\n",
      "Epoch 36/200, train_cost = 50.036, train_ler = 0.364, val_cost = 265.027, val_ler = 0.750, time = 0.123\n",
      "Epoch 37/200, train_cost = 48.126, train_ler = 0.409, val_cost = 266.376, val_ler = 0.750, time = 0.191\n",
      "Epoch 38/200, train_cost = 46.736, train_ler = 0.409, val_cost = 268.260, val_ler = 0.750, time = 0.161\n",
      "Epoch 39/200, train_cost = 45.345, train_ler = 0.386, val_cost = 270.225, val_ler = 0.750, time = 0.128\n",
      "Epoch 40/200, train_cost = 44.142, train_ler = 0.432, val_cost = 308.830, val_ler = 1.125, time = 0.108\n",
      "Epoch 41/200, train_cost = 54.942, train_ler = 0.432, val_cost = 289.197, val_ler = 0.792, time = 0.128\n",
      "Epoch 42/200, train_cost = 45.097, train_ler = 0.364, val_cost = 275.234, val_ler = 0.792, time = 0.124\n",
      "Epoch 43/200, train_cost = 45.123, train_ler = 0.318, val_cost = 277.671, val_ler = 0.792, time = 0.127\n",
      "Epoch 44/200, train_cost = 42.300, train_ler = 0.295, val_cost = 281.414, val_ler = 0.875, time = 0.109\n",
      "Epoch 45/200, train_cost = 41.247, train_ler = 0.318, val_cost = 281.213, val_ler = 0.833, time = 0.114\n",
      "Epoch 46/200, train_cost = 39.682, train_ler = 0.364, val_cost = 281.190, val_ler = 1.083, time = 0.121\n",
      "Epoch 47/200, train_cost = 38.899, train_ler = 0.273, val_cost = 291.792, val_ler = 0.917, time = 0.122\n",
      "Epoch 48/200, train_cost = 37.629, train_ler = 0.295, val_cost = 291.104, val_ler = 1.167, time = 0.127\n",
      "Epoch 49/200, train_cost = 36.382, train_ler = 0.273, val_cost = 291.523, val_ler = 0.958, time = 0.136\n",
      "Epoch 50/200, train_cost = 35.754, train_ler = 0.227, val_cost = 304.753, val_ler = 1.083, time = 0.137\n",
      "Epoch 51/200, train_cost = 35.112, train_ler = 0.205, val_cost = 306.368, val_ler = 0.958, time = 0.136\n",
      "Epoch 52/200, train_cost = 33.922, train_ler = 0.250, val_cost = 302.864, val_ler = 1.000, time = 0.112\n",
      "Epoch 53/200, train_cost = 32.416, train_ler = 0.273, val_cost = 302.904, val_ler = 0.917, time = 0.152\n",
      "Epoch 54/200, train_cost = 31.647, train_ler = 0.273, val_cost = 299.420, val_ler = 0.917, time = 0.118\n",
      "Epoch 55/200, train_cost = 32.152, train_ler = 0.295, val_cost = 310.360, val_ler = 1.000, time = 0.116\n",
      "Epoch 56/200, train_cost = 30.737, train_ler = 0.205, val_cost = 313.961, val_ler = 1.083, time = 0.130\n",
      "Epoch 57/200, train_cost = 29.332, train_ler = 0.159, val_cost = 312.094, val_ler = 1.125, time = 0.116\n",
      "Epoch 58/200, train_cost = 28.835, train_ler = 0.182, val_cost = 317.344, val_ler = 1.167, time = 0.142\n",
      "Epoch 59/200, train_cost = 27.893, train_ler = 0.227, val_cost = 329.895, val_ler = 1.250, time = 0.144\n",
      "Epoch 60/200, train_cost = 26.552, train_ler = 0.159, val_cost = 350.035, val_ler = 1.417, time = 0.122\n",
      "Epoch 61/200, train_cost = 26.172, train_ler = 0.136, val_cost = 359.656, val_ler = 1.417, time = 0.126\n",
      "Epoch 62/200, train_cost = 24.557, train_ler = 0.114, val_cost = 363.519, val_ler = 1.375, time = 0.117\n",
      "Epoch 63/200, train_cost = 23.662, train_ler = 0.114, val_cost = 371.953, val_ler = 1.375, time = 0.123\n",
      "Epoch 64/200, train_cost = 22.621, train_ler = 0.114, val_cost = 386.544, val_ler = 1.667, time = 0.130\n",
      "Epoch 65/200, train_cost = 21.705, train_ler = 0.068, val_cost = 394.003, val_ler = 1.667, time = 0.132\n",
      "Epoch 66/200, train_cost = 20.630, train_ler = 0.091, val_cost = 399.962, val_ler = 1.542, time = 0.146\n",
      "Epoch 67/200, train_cost = 19.843, train_ler = 0.045, val_cost = 412.038, val_ler = 1.625, time = 0.152\n",
      "Epoch 68/200, train_cost = 18.969, train_ler = 0.023, val_cost = 426.696, val_ler = 1.792, time = 0.114\n",
      "Epoch 69/200, train_cost = 17.991, train_ler = 0.045, val_cost = 432.219, val_ler = 1.708, time = 0.112\n",
      "Epoch 70/200, train_cost = 17.125, train_ler = 0.091, val_cost = 430.085, val_ler = 1.583, time = 0.110\n",
      "Epoch 71/200, train_cost = 16.350, train_ler = 0.068, val_cost = 431.660, val_ler = 1.583, time = 0.134\n",
      "Epoch 72/200, train_cost = 15.702, train_ler = 0.023, val_cost = 439.662, val_ler = 1.958, time = 0.123\n",
      "Epoch 73/200, train_cost = 14.858, train_ler = 0.000, val_cost = 446.668, val_ler = 1.958, time = 0.113\n",
      "Epoch 74/200, train_cost = 14.150, train_ler = 0.000, val_cost = 449.521, val_ler = 2.000, time = 0.113\n",
      "Epoch 75/200, train_cost = 13.425, train_ler = 0.023, val_cost = 449.596, val_ler = 1.958, time = 0.118\n",
      "Epoch 76/200, train_cost = 12.850, train_ler = 0.023, val_cost = 451.398, val_ler = 1.875, time = 0.110\n",
      "Epoch 77/200, train_cost = 12.188, train_ler = 0.000, val_cost = 454.912, val_ler = 1.875, time = 0.132\n",
      "Epoch 78/200, train_cost = 11.527, train_ler = 0.000, val_cost = 458.667, val_ler = 1.875, time = 0.134\n",
      "Epoch 79/200, train_cost = 11.002, train_ler = 0.000, val_cost = 462.840, val_ler = 1.958, time = 0.125\n",
      "Epoch 80/200, train_cost = 10.425, train_ler = 0.000, val_cost = 468.954, val_ler = 1.875, time = 0.133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200, train_cost = 9.869, train_ler = 0.000, val_cost = 475.664, val_ler = 1.875, time = 0.123\n",
      "Epoch 82/200, train_cost = 9.394, train_ler = 0.000, val_cost = 481.864, val_ler = 1.833, time = 0.107\n",
      "Epoch 83/200, train_cost = 8.923, train_ler = 0.000, val_cost = 486.831, val_ler = 1.917, time = 0.119\n",
      "Epoch 84/200, train_cost = 8.481, train_ler = 0.000, val_cost = 490.295, val_ler = 2.042, time = 0.116\n",
      "Epoch 85/200, train_cost = 8.066, train_ler = 0.000, val_cost = 492.891, val_ler = 2.042, time = 0.144\n",
      "Epoch 86/200, train_cost = 7.671, train_ler = 0.000, val_cost = 495.005, val_ler = 2.042, time = 0.133\n",
      "Epoch 87/200, train_cost = 7.291, train_ler = 0.000, val_cost = 496.810, val_ler = 1.958, time = 0.130\n",
      "Epoch 88/200, train_cost = 6.935, train_ler = 0.000, val_cost = 498.655, val_ler = 1.875, time = 0.115\n",
      "Epoch 89/200, train_cost = 6.611, train_ler = 0.000, val_cost = 500.398, val_ler = 1.875, time = 0.122\n",
      "Epoch 90/200, train_cost = 6.308, train_ler = 0.000, val_cost = 501.689, val_ler = 1.875, time = 0.104\n",
      "Epoch 91/200, train_cost = 6.015, train_ler = 0.000, val_cost = 502.282, val_ler = 1.875, time = 0.103\n",
      "Epoch 92/200, train_cost = 5.743, train_ler = 0.000, val_cost = 502.260, val_ler = 1.875, time = 0.110\n",
      "Epoch 93/200, train_cost = 5.491, train_ler = 0.000, val_cost = 502.008, val_ler = 1.875, time = 0.102\n",
      "Epoch 94/200, train_cost = 5.248, train_ler = 0.000, val_cost = 501.914, val_ler = 1.958, time = 0.117\n",
      "Epoch 95/200, train_cost = 5.017, train_ler = 0.000, val_cost = 502.167, val_ler = 1.958, time = 0.141\n",
      "Epoch 96/200, train_cost = 4.808, train_ler = 0.000, val_cost = 502.763, val_ler = 1.958, time = 0.147\n",
      "Epoch 97/200, train_cost = 4.612, train_ler = 0.000, val_cost = 503.597, val_ler = 1.917, time = 0.117\n",
      "Epoch 98/200, train_cost = 4.423, train_ler = 0.000, val_cost = 504.527, val_ler = 1.875, time = 0.113\n",
      "Epoch 99/200, train_cost = 4.244, train_ler = 0.000, val_cost = 505.452, val_ler = 1.875, time = 0.112\n",
      "Epoch 100/200, train_cost = 4.077, train_ler = 0.000, val_cost = 506.357, val_ler = 1.875, time = 0.121\n",
      "Epoch 101/200, train_cost = 3.920, train_ler = 0.000, val_cost = 507.295, val_ler = 1.875, time = 0.112\n",
      "Epoch 102/200, train_cost = 3.770, train_ler = 0.000, val_cost = 508.324, val_ler = 1.792, time = 0.114\n",
      "Epoch 103/200, train_cost = 3.629, train_ler = 0.000, val_cost = 509.481, val_ler = 1.875, time = 0.111\n",
      "Epoch 104/200, train_cost = 3.495, train_ler = 0.000, val_cost = 510.779, val_ler = 1.917, time = 0.152\n",
      "Epoch 105/200, train_cost = 3.368, train_ler = 0.000, val_cost = 512.194, val_ler = 1.917, time = 0.118\n",
      "Epoch 106/200, train_cost = 3.247, train_ler = 0.000, val_cost = 513.675, val_ler = 1.917, time = 0.106\n",
      "Epoch 107/200, train_cost = 3.134, train_ler = 0.000, val_cost = 515.155, val_ler = 1.875, time = 0.122\n",
      "Epoch 108/200, train_cost = 3.025, train_ler = 0.000, val_cost = 516.574, val_ler = 1.958, time = 0.129\n",
      "Epoch 109/200, train_cost = 2.921, train_ler = 0.000, val_cost = 517.901, val_ler = 1.958, time = 0.135\n",
      "Epoch 110/200, train_cost = 2.822, train_ler = 0.000, val_cost = 519.151, val_ler = 2.000, time = 0.119\n",
      "Epoch 111/200, train_cost = 2.728, train_ler = 0.000, val_cost = 520.362, val_ler = 1.917, time = 0.111\n",
      "Epoch 112/200, train_cost = 2.640, train_ler = 0.000, val_cost = 521.579, val_ler = 1.917, time = 0.115\n",
      "Epoch 113/200, train_cost = 2.555, train_ler = 0.000, val_cost = 522.839, val_ler = 1.917, time = 0.128\n",
      "Epoch 114/200, train_cost = 2.475, train_ler = 0.000, val_cost = 524.165, val_ler = 1.875, time = 0.109\n",
      "Epoch 115/200, train_cost = 2.398, train_ler = 0.000, val_cost = 525.543, val_ler = 1.875, time = 0.106\n",
      "Epoch 116/200, train_cost = 2.326, train_ler = 0.000, val_cost = 526.945, val_ler = 1.958, time = 0.130\n",
      "Epoch 117/200, train_cost = 2.257, train_ler = 0.000, val_cost = 528.335, val_ler = 1.958, time = 0.109\n",
      "Epoch 118/200, train_cost = 2.191, train_ler = 0.000, val_cost = 529.684, val_ler = 1.917, time = 0.117\n",
      "Epoch 119/200, train_cost = 2.127, train_ler = 0.000, val_cost = 530.981, val_ler = 1.917, time = 0.127\n",
      "Epoch 120/200, train_cost = 2.066, train_ler = 0.000, val_cost = 532.224, val_ler = 2.083, time = 0.128\n",
      "Epoch 121/200, train_cost = 2.009, train_ler = 0.000, val_cost = 533.413, val_ler = 2.042, time = 0.128\n",
      "Epoch 122/200, train_cost = 1.953, train_ler = 0.000, val_cost = 534.547, val_ler = 2.000, time = 0.132\n",
      "Epoch 123/200, train_cost = 1.900, train_ler = 0.000, val_cost = 535.629, val_ler = 2.000, time = 0.118\n",
      "Epoch 124/200, train_cost = 1.849, train_ler = 0.000, val_cost = 536.674, val_ler = 2.000, time = 0.121\n",
      "Epoch 125/200, train_cost = 1.800, train_ler = 0.000, val_cost = 537.704, val_ler = 2.000, time = 0.154\n",
      "Epoch 126/200, train_cost = 1.753, train_ler = 0.000, val_cost = 538.745, val_ler = 2.083, time = 0.132\n",
      "Epoch 127/200, train_cost = 1.708, train_ler = 0.000, val_cost = 539.802, val_ler = 2.083, time = 0.115\n",
      "Epoch 128/200, train_cost = 1.665, train_ler = 0.000, val_cost = 540.859, val_ler = 2.125, time = 0.115\n",
      "Epoch 129/200, train_cost = 1.624, train_ler = 0.000, val_cost = 541.893, val_ler = 2.125, time = 0.110\n",
      "Epoch 130/200, train_cost = 1.585, train_ler = 0.000, val_cost = 542.891, val_ler = 2.167, time = 0.115\n",
      "Epoch 131/200, train_cost = 1.549, train_ler = 0.000, val_cost = 543.857, val_ler = 2.167, time = 0.108\n",
      "Epoch 132/200, train_cost = 1.513, train_ler = 0.000, val_cost = 544.814, val_ler = 2.125, time = 0.106\n",
      "Epoch 133/200, train_cost = 1.479, train_ler = 0.000, val_cost = 545.794, val_ler = 2.208, time = 0.115\n",
      "Epoch 134/200, train_cost = 1.447, train_ler = 0.000, val_cost = 546.824, val_ler = 2.250, time = 0.129\n",
      "Epoch 135/200, train_cost = 1.415, train_ler = 0.000, val_cost = 547.908, val_ler = 2.250, time = 0.128\n",
      "Epoch 136/200, train_cost = 1.384, train_ler = 0.000, val_cost = 549.030, val_ler = 2.250, time = 0.118\n",
      "Epoch 137/200, train_cost = 1.355, train_ler = 0.000, val_cost = 550.154, val_ler = 2.292, time = 0.123\n",
      "Epoch 138/200, train_cost = 1.327, train_ler = 0.000, val_cost = 551.249, val_ler = 2.292, time = 0.133\n",
      "Epoch 139/200, train_cost = 1.300, train_ler = 0.000, val_cost = 552.289, val_ler = 2.292, time = 0.114\n",
      "Epoch 140/200, train_cost = 1.274, train_ler = 0.000, val_cost = 553.264, val_ler = 2.292, time = 0.107\n",
      "Epoch 141/200, train_cost = 1.249, train_ler = 0.000, val_cost = 554.181, val_ler = 2.292, time = 0.112\n",
      "Epoch 142/200, train_cost = 1.225, train_ler = 0.000, val_cost = 555.057, val_ler = 2.292, time = 0.126\n",
      "Epoch 143/200, train_cost = 1.202, train_ler = 0.000, val_cost = 555.907, val_ler = 2.292, time = 0.173\n",
      "Epoch 144/200, train_cost = 1.180, train_ler = 0.000, val_cost = 556.743, val_ler = 2.292, time = 0.155\n",
      "Epoch 145/200, train_cost = 1.158, train_ler = 0.000, val_cost = 557.571, val_ler = 2.292, time = 0.132\n",
      "Epoch 146/200, train_cost = 1.137, train_ler = 0.000, val_cost = 558.387, val_ler = 2.292, time = 0.126\n",
      "Epoch 147/200, train_cost = 1.117, train_ler = 0.000, val_cost = 559.186, val_ler = 2.208, time = 0.127\n",
      "Epoch 148/200, train_cost = 1.097, train_ler = 0.000, val_cost = 559.961, val_ler = 2.208, time = 0.138\n",
      "Epoch 149/200, train_cost = 1.078, train_ler = 0.000, val_cost = 560.713, val_ler = 2.250, time = 0.137\n",
      "Epoch 150/200, train_cost = 1.060, train_ler = 0.000, val_cost = 561.443, val_ler = 2.250, time = 0.134\n",
      "Epoch 151/200, train_cost = 1.042, train_ler = 0.000, val_cost = 562.161, val_ler = 2.250, time = 0.133\n",
      "Epoch 152/200, train_cost = 1.025, train_ler = 0.000, val_cost = 562.878, val_ler = 2.250, time = 0.142\n",
      "Epoch 153/200, train_cost = 1.009, train_ler = 0.000, val_cost = 563.604, val_ler = 2.292, time = 0.131\n",
      "Epoch 154/200, train_cost = 0.993, train_ler = 0.000, val_cost = 564.344, val_ler = 2.292, time = 0.142\n",
      "Epoch 155/200, train_cost = 0.977, train_ler = 0.000, val_cost = 565.098, val_ler = 2.292, time = 0.152\n",
      "Epoch 156/200, train_cost = 0.962, train_ler = 0.000, val_cost = 565.860, val_ler = 2.292, time = 0.145\n",
      "Epoch 157/200, train_cost = 0.947, train_ler = 0.000, val_cost = 566.625, val_ler = 2.333, time = 0.138\n",
      "Epoch 158/200, train_cost = 0.933, train_ler = 0.000, val_cost = 567.385, val_ler = 2.333, time = 0.136\n",
      "Epoch 159/200, train_cost = 0.919, train_ler = 0.000, val_cost = 568.136, val_ler = 2.333, time = 0.152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200, train_cost = 0.905, train_ler = 0.000, val_cost = 568.878, val_ler = 2.333, time = 0.140\n",
      "Epoch 161/200, train_cost = 0.892, train_ler = 0.000, val_cost = 569.613, val_ler = 2.333, time = 0.123\n",
      "Epoch 162/200, train_cost = 0.879, train_ler = 0.000, val_cost = 570.345, val_ler = 2.333, time = 0.133\n",
      "Epoch 163/200, train_cost = 0.867, train_ler = 0.000, val_cost = 571.077, val_ler = 2.333, time = 0.150\n",
      "Epoch 164/200, train_cost = 0.855, train_ler = 0.000, val_cost = 571.810, val_ler = 2.292, time = 0.154\n",
      "Epoch 165/200, train_cost = 0.843, train_ler = 0.000, val_cost = 572.544, val_ler = 2.292, time = 0.137\n",
      "Epoch 166/200, train_cost = 0.832, train_ler = 0.000, val_cost = 573.274, val_ler = 2.292, time = 0.147\n",
      "Epoch 167/200, train_cost = 0.820, train_ler = 0.000, val_cost = 573.996, val_ler = 2.292, time = 0.161\n",
      "Epoch 168/200, train_cost = 0.809, train_ler = 0.000, val_cost = 574.706, val_ler = 2.292, time = 0.144\n",
      "Epoch 169/200, train_cost = 0.799, train_ler = 0.000, val_cost = 575.400, val_ler = 2.292, time = 0.128\n",
      "Epoch 170/200, train_cost = 0.789, train_ler = 0.000, val_cost = 576.080, val_ler = 2.375, time = 0.134\n",
      "Epoch 171/200, train_cost = 0.778, train_ler = 0.000, val_cost = 576.745, val_ler = 2.375, time = 0.128\n",
      "Epoch 172/200, train_cost = 0.769, train_ler = 0.000, val_cost = 577.399, val_ler = 2.375, time = 0.124\n",
      "Epoch 173/200, train_cost = 0.759, train_ler = 0.000, val_cost = 578.046, val_ler = 2.375, time = 0.145\n",
      "Epoch 174/200, train_cost = 0.750, train_ler = 0.000, val_cost = 578.689, val_ler = 2.375, time = 0.142\n",
      "Epoch 175/200, train_cost = 0.740, train_ler = 0.000, val_cost = 579.331, val_ler = 2.375, time = 0.145\n",
      "Epoch 176/200, train_cost = 0.731, train_ler = 0.000, val_cost = 579.973, val_ler = 2.375, time = 0.171\n",
      "Epoch 177/200, train_cost = 0.723, train_ler = 0.000, val_cost = 580.617, val_ler = 2.375, time = 0.138\n",
      "Epoch 178/200, train_cost = 0.714, train_ler = 0.000, val_cost = 581.261, val_ler = 2.375, time = 0.145\n",
      "Epoch 179/200, train_cost = 0.706, train_ler = 0.000, val_cost = 581.903, val_ler = 2.375, time = 0.143\n",
      "Epoch 180/200, train_cost = 0.697, train_ler = 0.000, val_cost = 582.541, val_ler = 2.375, time = 0.134\n",
      "Epoch 181/200, train_cost = 0.689, train_ler = 0.000, val_cost = 583.174, val_ler = 2.375, time = 0.179\n",
      "Epoch 182/200, train_cost = 0.682, train_ler = 0.000, val_cost = 583.802, val_ler = 2.375, time = 0.147\n",
      "Epoch 183/200, train_cost = 0.674, train_ler = 0.000, val_cost = 584.423, val_ler = 2.375, time = 0.144\n",
      "Epoch 184/200, train_cost = 0.666, train_ler = 0.000, val_cost = 585.038, val_ler = 2.375, time = 0.125\n",
      "Epoch 185/200, train_cost = 0.659, train_ler = 0.000, val_cost = 585.647, val_ler = 2.292, time = 0.117\n",
      "Epoch 186/200, train_cost = 0.652, train_ler = 0.000, val_cost = 586.249, val_ler = 2.292, time = 0.115\n",
      "Epoch 187/200, train_cost = 0.645, train_ler = 0.000, val_cost = 586.845, val_ler = 2.292, time = 0.119\n",
      "Epoch 188/200, train_cost = 0.638, train_ler = 0.000, val_cost = 587.435, val_ler = 2.292, time = 0.134\n",
      "Epoch 189/200, train_cost = 0.631, train_ler = 0.000, val_cost = 588.017, val_ler = 2.292, time = 0.131\n",
      "Epoch 190/200, train_cost = 0.625, train_ler = 0.000, val_cost = 588.592, val_ler = 2.292, time = 0.125\n",
      "Epoch 191/200, train_cost = 0.618, train_ler = 0.000, val_cost = 589.160, val_ler = 2.292, time = 0.110\n",
      "Epoch 192/200, train_cost = 0.612, train_ler = 0.000, val_cost = 589.723, val_ler = 2.292, time = 0.124\n",
      "Epoch 193/200, train_cost = 0.605, train_ler = 0.000, val_cost = 590.280, val_ler = 2.292, time = 0.127\n",
      "Epoch 194/200, train_cost = 0.599, train_ler = 0.000, val_cost = 590.832, val_ler = 2.292, time = 0.136\n",
      "Epoch 195/200, train_cost = 0.593, train_ler = 0.000, val_cost = 591.381, val_ler = 2.292, time = 0.125\n",
      "Epoch 196/200, train_cost = 0.587, train_ler = 0.000, val_cost = 591.927, val_ler = 2.292, time = 0.139\n",
      "Epoch 197/200, train_cost = 0.582, train_ler = 0.000, val_cost = 592.472, val_ler = 2.292, time = 0.121\n",
      "Epoch 198/200, train_cost = 0.576, train_ler = 0.000, val_cost = 593.016, val_ler = 2.292, time = 0.121\n",
      "Epoch 199/200, train_cost = 0.570, train_ler = 0.000, val_cost = 593.559, val_ler = 2.292, time = 0.127\n",
      "Epoch 200/200, train_cost = 0.565, train_ler = 0.000, val_cost = 594.100, val_ler = 2.292, time = 0.148\n",
      "Original:\n",
      "fortune and a happy life\n",
      "Decoded:\n",
      "l a g gg g rlyy  asaseasyaswyw tr  ad y y ha t iti titi t t t ti \n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    # TensorBoard\n",
    "    train_summary_writer = tf.summary.FileWriter('./logs/ctc/train', session.graph)\n",
    "    val_summary_writer = tf.summary.FileWriter('./logs/ctc/val', session.graph)\n",
    "\n",
    "    for curr_epoch in range(num_epochs):\n",
    "        train_cost = train_ler = 0\n",
    "        start = time.time()\n",
    "\n",
    "        for batch in range(num_batches_per_epoch):\n",
    "\n",
    "            feed = {inputs: train_input,\n",
    "                    targets: train_targets,\n",
    "                    seq_len: train_seq_len}\n",
    "\n",
    "            batch_cost, _, summary = session.run([cost, optimizer, summary_op], feed)\n",
    "            train_summary_writer.add_summary(summary, curr_epoch * num_batches_per_epoch + batch)\n",
    "            \n",
    "            train_cost += batch_cost*batch_size\n",
    "            train_ler += session.run(ler, feed_dict=feed)*batch_size\n",
    "            \n",
    "        train_cost /= num_examples\n",
    "        train_ler /= num_examples\n",
    "\n",
    "        val_feed = {inputs: val_input,\n",
    "                    targets: val_targets,\n",
    "                    seq_len: val_seq_len}\n",
    "\n",
    "        val_cost, val_ler, val_summary = session.run([cost, ler, summary_op], feed_dict=val_feed)\n",
    "        val_summary_writer.add_summary(val_summary, curr_epoch * num_batches_per_epoch * batch_size)\n",
    "        \n",
    "        log = \"Epoch {}/{}, train_cost = {:.3f}, train_ler = {:.3f}, val_cost = {:.3f}, val_ler = {:.3f}, time = {:.3f}\"\n",
    "        print(log.format(curr_epoch+1, num_epochs, train_cost, train_ler,\n",
    "                         val_cost, val_ler, time.time() - start))\n",
    "    # Decoding\n",
    "    d = session.run(decoded[0], feed_dict=val_feed)\n",
    "    str_decoded = ''.join([chr(x) for x in np.asarray(d[1]) + FIRST_INDEX])\n",
    "\n",
    "    # Replacing blank label to none\n",
    "    str_decoded = str_decoded.replace(chr(ord('z') + 1), '')\n",
    "\n",
    "    # Replacing space label to space\n",
    "    str_decoded = str_decoded.replace(chr(ord('a') - 1), ' ')\n",
    "\n",
    "    print('Original:\\n%s' % val_original)\n",
    "    print('Decoded:\\n%s' % str_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep Speech\n",
    "\n",
    "Deep Speech 1: https://arxiv.org/abs/1412.5567\n",
    "\n",
    "Deep Speech 2: https://arxiv.org/abs/1512.02595"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workshop: Deep Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "livereveal": {
   "autolaunch": true,
   "overlay": "<div class='logo'><img src='assets/Stackup_Logo_Small.png' width='90%'/></div>"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
