{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition\n",
    "\n",
    "A survey of statistical and deep learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conventional (Statistical) Pipeline\n",
    "\n",
    "<img src='assets/speech/asr-pipeline.jpg'/>\n",
    "\n",
    "\n",
    "Source: https://www.techrepublic.com/article/how-we-learned-to-talk-to-computers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Speech Feature Extraction\n",
    "\n",
    "<img src='assets/speech/Spectrogram-19thC.png'/>\n",
    "\n",
    "A spectrogram for \"nineteen century\" - power vs. frequency\n",
    "\n",
    "Common method: Mel-frequency cepstral coefficients (MFCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical Speech Recognition\n",
    "\n",
    "$$W^* = \\underset{W}{\\operatorname{argmax}}P(W|X)$$\n",
    "\n",
    "word sequence: $W$\n",
    "\n",
    "most likely word sequence: $W^*$\n",
    "\n",
    "acoustic input feature vector (e.g. MFCC): $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical Speech Recognition\n",
    "\n",
    "After Bayes' Theorem:\n",
    "\n",
    "$$W^* = \\underset{W}{\\operatorname{argmax}}p(X|W)P(W)$$\n",
    "\n",
    "acoustic model: $p(X|W)$\n",
    "\n",
    "language model (e.g. N-gram): $P(W)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical Acoustic Model: $p(X|W)$\n",
    "\n",
    "<img src='assets/speech/acoustic-statistical.png' width='50%'/>\n",
    "\n",
    "Credits: https://www.inf.ed.ac.uk/teaching/courses/asr/2016-17/asr03-hmmgmm-handout.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hidden Markov Model: $p(S_i|S_{i-1})$, Gaussian Mixture Model: $p(X|S_i)$\n",
    "\n",
    "<img src='assets/speech/acoustic-hmm-gmm.png' width='50%'/>\n",
    "\n",
    "Credits: https://www.inf.ed.ac.uk/teaching/courses/asr/2016-17/asr03-hmmgmm-handout.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Model\n",
    "\n",
    "Mixture distribution: combine multiple probabability distributions to make an improved model\n",
    "\n",
    "$$P(x) = \\sum_iP(c=i)P(x \\mid c=i)$$\n",
    "\n",
    "$i^{th}$ Gaussian component: $P(x \\mid c=i)$\n",
    "\n",
    "Applications\n",
    "- Clustering\n",
    "- Classification\n",
    "\n",
    "Nice intro:\n",
    "https://yulearning.blogspot.sg/2014/11/einsteins-most-famous-equation-is-emc2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workshop: GMM gender detector\n",
    "\n",
    "Credits: https://github.com/abhijeet3922/PyGender-Voice\n",
    "\n",
    "<img src='assets/speech/workshop1_pygender.png' style='float:right'/>\n",
    "\n",
    "1. Download data from [here](\n",
    "https://www.dropbox.com/s/hcku4t7alrhacqv/pygender.zip?dl=0)\n",
    "\n",
    "2. Extract the .zip file to a folder of your choice. Note down the path as you will need to enter it in the workshop code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install python_speech_features\n",
    "\n",
    "import os\n",
    "from os.path import basename, join\n",
    "import numpy as np\n",
    "\n",
    "import python_speech_features as mfcc\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn import preprocessing\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "TRAIN_PATH = 'C:\\\\mldds\\\\pygender\\\\train_data\\\\youtube\\\\' # modify to your actual path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_MFCC(audio_file, scale=True):\n",
    "    '''Computes the Mel-frequency ceptrum coefficients for an audio file,\n",
    "    with optional scaling\n",
    "    See: https://github.com/jameslyons/python_speech_features\n",
    "    '''\n",
    "    sample_rate, audio = read(audio_file)\n",
    "    features = mfcc.mfcc(audio, sample_rate, winlen=0.025, winstep=0.01, numcep=13, appendEnergy=False)\n",
    "    if scale:\n",
    "        features = preprocessing.scale(features) # scale to (0, 1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Playback a sample file\n",
    "from IPython import display\n",
    "\n",
    "sample_file = join(TRAIN_PATH, 'male', 'male1.wav')\n",
    "sample_rate, audio = read(sample_file)\n",
    "display.Audio(data=audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the MFCC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mfcc_vector = get_MFCC(sample_file, scale=False)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20,4))\n",
    "cax = ax.matshow(np.transpose(mfcc_vector), interpolation='nearest', aspect='auto', cmap='coolwarm', origin='lower')\n",
    "fig.colorbar(cax)\n",
    "plt.title(\"Spectrogram of {}\".format(sample_file))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def train_GMM(data_path, n_components=8, covariance_type='diag'):\n",
    "    '''Trains a Gaussian mixture model for a given label and data path'''\n",
    "    files = [join(data_path, f) for f in os.listdir(data_path) if f.endswith('.wav')]\n",
    "    features = np.asarray(());\n",
    "\n",
    "    for f in files:\n",
    "        mfcc_vector = get_MFCC(f)\n",
    "\n",
    "        if features.size:\n",
    "            features = np.vstack((features, mfcc_vector))\n",
    "        else:\n",
    "            features = mfcc_vector\n",
    "\n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html\n",
    "    gmm = GaussianMixture(n_components=n_components, covariance_type=covariance_type,\n",
    "                          max_iter=200, n_init=3)\n",
    "    gmm.fit(features)\n",
    "    \n",
    "    # print some metrics applicable to GMMs\n",
    "    print('BIC: ', gmm.bic(features), ', AIC: ', gmm.aic(features))\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "models = dict()\n",
    "%time models['male'] = train_GMM(join(TRAIN_PATH, 'male'), n_components=8, covariance_type='diag')\n",
    "\n",
    "# ==================================================================\n",
    "# Exercise:\n",
    "# Add code below to train the female model, using the above as an example\n",
    "\n",
    "## === ANSWER === ##\n",
    "%time models['female'] = train_GMM(join(TRAIN_PATH, 'female'), n_components=8, covariance_type='diag')\n",
    "## === ANSWER === ##\n",
    "\n",
    "# ==================================================================\n",
    "# Optional Exercises:\n",
    "# a. Try different values of n_component (e.g. 2, 16)\n",
    "# b. Try different values of covariance_type (e.g. full)\n",
    "#\n",
    "# See http://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html\n",
    "# on how to interpret the BIC and AIC metrics for selecting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def test_GMM(models, test_data_path):\n",
    "    '''Tests multiple Gaussian mixture models with test data'''\n",
    "    files = [os.path.join(test_data_path,f) for f in os.listdir(test_data_path)\n",
    "             if f.endswith(\".wav\")]\n",
    "    \n",
    "    predictions = []\n",
    "    for f in files:\n",
    "        features = get_MFCC(f)\n",
    "        keys = []\n",
    "        log_likelihood = np.zeros(len(models))\n",
    "\n",
    "        for i, (key, gmm) in enumerate(models.items()):\n",
    "            scores = np.array(gmm.score(features))\n",
    "            keys.append(key)\n",
    "            log_likelihood[i] = scores.sum()\n",
    "\n",
    "        # find the model with the maximum score\n",
    "        winner = np.argmax(log_likelihood)\n",
    "        # print('prediction:', keys[winner], \"\\tscores:\", log_likelihood[winner])\n",
    "        predictions.append(keys[winner])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# ==================================================================\n",
    "# Exercise:\n",
    "# 1. Complete the code below to test the GMM models using test_GMM().\n",
    "#    Be sure to run against both male and female models.\n",
    "# 2. Plot the confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "TEST_PATH = 'C:\\\\mldds\\\\pygender\\\\test_data\\\\AudioSet' # modify to your actual path\n",
    "\n",
    "## === ANSWER === ##\n",
    "male_predictions = test_GMM(models, join(TEST_PATH, 'male_clips'))\n",
    "female_predictions = test_GMM(models, join(TEST_PATH, 'female_clips'))\n",
    "\n",
    "truth = ['male' for p in male_predictions] + ['female' for p in female_predictions]\n",
    "cm = confusion_matrix(truth, male_predictions + female_predictions)\n",
    "print(cm)\n",
    "plt.matshow(cm)\n",
    "plt.colorbar()\n",
    "## === ANSWER === ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Shortcomings of Statistical Approaches\n",
    "\n",
    "Lots of hand-tuning\n",
    "\n",
    "Inefficient for approximating non-linear data: covariance matrices get very large\n",
    "\n",
    "Solution: deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## HMM-DNN\n",
    "\n",
    "Paper:\n",
    "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38131.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recurrent Neural Networks\n",
    "\n",
    "Paper: http://proceedings.mlr.press/v32/graves14.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workshop: Deep Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "livereveal": {
   "autolaunch": true,
   "overlay": "<div class='logo'><img src='assets/Stackup_Logo_Small.png' width='90%'/></div>"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
