{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Team</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>Goal Scored</th>\n",
       "      <th>Ball Possession %</th>\n",
       "      <th>Attempts</th>\n",
       "      <th>On-Target</th>\n",
       "      <th>Off-Target</th>\n",
       "      <th>Blocked</th>\n",
       "      <th>Corners</th>\n",
       "      <th>...</th>\n",
       "      <th>Yellow Card</th>\n",
       "      <th>Yellow &amp; Red</th>\n",
       "      <th>Red</th>\n",
       "      <th>Man of the Match</th>\n",
       "      <th>1st Goal</th>\n",
       "      <th>Round</th>\n",
       "      <th>PSO</th>\n",
       "      <th>Goals in PSO</th>\n",
       "      <th>Own goals</th>\n",
       "      <th>Own goal Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14-06-2018</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14-06-2018</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-06-2018</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-06-2018</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>89.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15-06-2018</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>Iran</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15-06-2018</td>\n",
       "      <td>Iran</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15-06-2018</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Spain</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15-06-2018</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16-06-2018</td>\n",
       "      <td>France</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16-06-2018</td>\n",
       "      <td>Australia</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>62.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16-06-2018</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16-06-2018</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16-06-2018</td>\n",
       "      <td>Peru</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16-06-2018</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>Peru</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17-06-2018</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17-06-2018</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17-06-2018</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17-06-2018</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17-06-2018</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17-06-2018</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17-06-2018</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17-06-2018</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18-06-2018</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Korea Republic</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18-06-2018</td>\n",
       "      <td>Korea Republic</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18-06-2018</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Panama</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>18-06-2018</td>\n",
       "      <td>Panama</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>18-06-2018</td>\n",
       "      <td>Tunisia</td>\n",
       "      <td>England</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18-06-2018</td>\n",
       "      <td>England</td>\n",
       "      <td>Tunisia</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>19-06-2018</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19-06-2018</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>30-06-2018</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>30-06-2018</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>01-07-2018</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Russia</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>01-07-2018</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>01-07-2018</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>01-07-2018</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>02-07-2018</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>02-07-2018</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>02-07-2018</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Japan</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>02-07-2018</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>03-07-2018</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>03-07-2018</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>03-07-2018</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>England</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>03-07-2018</td>\n",
       "      <td>England</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>06-07-2018</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quarter Finals</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>06-07-2018</td>\n",
       "      <td>France</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Quarter Finals</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>06-07-2018</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quarter Finals</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>06-07-2018</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Quarter Finals</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>07-07-2018</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>England</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quarter Finals</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>07-07-2018</td>\n",
       "      <td>England</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Quarter Finals</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>07-07-2018</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Quarter Finals</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>07-07-2018</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Quarter Finals</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>10-07-2018</td>\n",
       "      <td>France</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Semi- Finals</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>10-07-2018</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Semi- Finals</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>11-07-2018</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>England</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Semi- Finals</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>11-07-2018</td>\n",
       "      <td>England</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Semi- Finals</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>14-07-2018</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>England</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3rd Place</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>14-07-2018</td>\n",
       "      <td>England</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3rd Place</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>15-07-2018</td>\n",
       "      <td>France</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Final</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>15-07-2018</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>France</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Final</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date            Team        Opponent  Goal Scored  \\\n",
       "0    14-06-2018          Russia    Saudi Arabia            5   \n",
       "1    14-06-2018    Saudi Arabia          Russia            0   \n",
       "2    15-06-2018           Egypt         Uruguay            0   \n",
       "3    15-06-2018         Uruguay           Egypt            1   \n",
       "4    15-06-2018         Morocco            Iran            0   \n",
       "5    15-06-2018            Iran         Morocco            1   \n",
       "6    15-06-2018        Portugal           Spain            3   \n",
       "7    15-06-2018           Spain        Portugal            3   \n",
       "8    16-06-2018          France       Australia            2   \n",
       "9    16-06-2018       Australia          France            1   \n",
       "10   16-06-2018       Argentina         Iceland            1   \n",
       "11   16-06-2018         Iceland       Argentina            1   \n",
       "12   16-06-2018            Peru         Denmark            0   \n",
       "13   16-06-2018         Denmark            Peru            1   \n",
       "14   17-06-2018         Croatia         Nigeria            2   \n",
       "15   17-06-2018         Nigeria         Croatia            0   \n",
       "16   17-06-2018      Costa Rica          Serbia            0   \n",
       "17   17-06-2018          Serbia      Costa Rica            1   \n",
       "18   17-06-2018         Germany          Mexico            0   \n",
       "19   17-06-2018          Mexico         Germany            1   \n",
       "20   17-06-2018          Brazil     Switzerland            1   \n",
       "21   17-06-2018     Switzerland          Brazil            1   \n",
       "22   18-06-2018          Sweden  Korea Republic            1   \n",
       "23   18-06-2018  Korea Republic          Sweden            0   \n",
       "24   18-06-2018         Belgium          Panama            3   \n",
       "25   18-06-2018          Panama         Belgium            0   \n",
       "26   18-06-2018         Tunisia         England            1   \n",
       "27   18-06-2018         England         Tunisia            2   \n",
       "28   19-06-2018        Colombia           Japan            1   \n",
       "29   19-06-2018           Japan        Colombia            2   \n",
       "..          ...             ...             ...          ...   \n",
       "98   30-06-2018         Uruguay        Portugal            2   \n",
       "99   30-06-2018        Portugal         Uruguay            1   \n",
       "100  01-07-2018           Spain          Russia            1   \n",
       "101  01-07-2018          Russia           Spain            1   \n",
       "102  01-07-2018         Croatia         Denmark            1   \n",
       "103  01-07-2018         Denmark         Croatia            1   \n",
       "104  02-07-2018          Brazil          Mexico            2   \n",
       "105  02-07-2018          Mexico          Brazil            0   \n",
       "106  02-07-2018         Belgium           Japan            3   \n",
       "107  02-07-2018           Japan         Belgium            2   \n",
       "108  03-07-2018          Sweden     Switzerland            1   \n",
       "109  03-07-2018     Switzerland          Sweden            0   \n",
       "110  03-07-2018        Colombia         England            1   \n",
       "111  03-07-2018         England        Colombia            1   \n",
       "112  06-07-2018         Uruguay          France            0   \n",
       "113  06-07-2018          France         Uruguay            2   \n",
       "114  06-07-2018          Brazil         Belgium            1   \n",
       "115  06-07-2018         Belgium          Brazil            2   \n",
       "116  07-07-2018          Sweden         England            0   \n",
       "117  07-07-2018         England          Sweden            2   \n",
       "118  07-07-2018          Russia         Croatia            2   \n",
       "119  07-07-2018         Croatia          Russia            2   \n",
       "120  10-07-2018          France         Belgium            1   \n",
       "121  10-07-2018         Belgium          France            0   \n",
       "122  11-07-2018         Croatia         England            2   \n",
       "123  11-07-2018         England         Croatia            1   \n",
       "124  14-07-2018         Belgium         England            2   \n",
       "125  14-07-2018         England         Belgium            0   \n",
       "126  15-07-2018          France         Croatia            4   \n",
       "127  15-07-2018         Croatia          France            2   \n",
       "\n",
       "     Ball Possession %  Attempts  On-Target  Off-Target  Blocked  Corners  \\\n",
       "0                   40        13          7           3        3        6   \n",
       "1                   60         6          0           3        3        2   \n",
       "2                   43         8          3           3        2        0   \n",
       "3                   57        14          4           6        4        5   \n",
       "4                   64        13          3           6        4        5   \n",
       "5                   36         8          2           5        1        2   \n",
       "6                   39         8          3           2        3        4   \n",
       "7                   61        12          5           5        2        5   \n",
       "8                   51        12          5           4        3        5   \n",
       "9                   49         4          1           2        1        1   \n",
       "10                  72        26          7           9       10       10   \n",
       "11                  28         9          3           5        1        2   \n",
       "12                  52        18          6           7        5        3   \n",
       "13                  48        10          3           5        2        7   \n",
       "14                  54        11          2           7        2        6   \n",
       "15                  46        14          2           5        7        5   \n",
       "16                  50        10          3           3        4        5   \n",
       "17                  50        10          3           5        2        4   \n",
       "18                  60        25          9           9        7        8   \n",
       "19                  40        12          4           6        2        1   \n",
       "20                  52        20          4           9        7        7   \n",
       "21                  48         6          2           4        0        2   \n",
       "22                  52        15          4           5        6        6   \n",
       "23                  48         5          0           2        3        5   \n",
       "24                  61        15          6           7        2        9   \n",
       "25                  39         6          2           4        0        3   \n",
       "26                  41         6          1           3        2        2   \n",
       "27                  59        17          7           7        3        7   \n",
       "28                  41         8          3           1        4        3   \n",
       "29                  59        14          6           5        3        6   \n",
       "..                 ...       ...        ...         ...      ...      ...   \n",
       "98                  39         6          3           2        1        2   \n",
       "99                  61        20          5           1        8       10   \n",
       "100                 75        25          9           6       10        6   \n",
       "101                 25         6          1           3        2        5   \n",
       "102                 54        22          7           8        7        5   \n",
       "103                 46        15          3          10        2        4   \n",
       "104                 47        21         10           7        4        8   \n",
       "105                 53        13          1           4        8        7   \n",
       "106                 56        24          8          10        6       10   \n",
       "107                 44        11          4           4        3        6   \n",
       "108                 37        12          3           6        3        3   \n",
       "109                 63        18          4           5        9       11   \n",
       "110                 48        14          4           7        3        2   \n",
       "111                 51        16          2           9        5        7   \n",
       "112                 42        11          4           6        1        4   \n",
       "113                 58        11          2           7        2        3   \n",
       "114                 57        26          9           7       10        8   \n",
       "115                 43         8          3           3        2        4   \n",
       "116                 43         7          3           3        1        1   \n",
       "117                 57        12          2           4        6        6   \n",
       "118                 38        13          7           4        2        6   \n",
       "119                 62        17          3          10        4        8   \n",
       "120                 40        19          5           8        6        4   \n",
       "121                 60         9          3           5        1        5   \n",
       "122                 54        22          7          11        4        8   \n",
       "123                 46        11          1           6        4        4   \n",
       "124                 43        12          4           3        5        4   \n",
       "125                 57        15          5           7        3        5   \n",
       "126                 39         8          6           1        1        2   \n",
       "127                 61        15          3           8        4        6   \n",
       "\n",
       "         ...        Yellow Card  Yellow & Red  Red  Man of the Match  \\\n",
       "0        ...                  0             0    0               Yes   \n",
       "1        ...                  0             0    0                No   \n",
       "2        ...                  2             0    0                No   \n",
       "3        ...                  0             0    0               Yes   \n",
       "4        ...                  1             0    0                No   \n",
       "5        ...                  3             0    0               Yes   \n",
       "6        ...                  1             0    0                No   \n",
       "7        ...                  1             0    0               Yes   \n",
       "8        ...                  1             0    0               Yes   \n",
       "9        ...                  3             0    0                No   \n",
       "10       ...                  0             0    0                No   \n",
       "11       ...                  0             0    0               Yes   \n",
       "12       ...                  1             0    0                No   \n",
       "13       ...                  2             0    0               Yes   \n",
       "14       ...                  2             0    0               Yes   \n",
       "15       ...                  1             0    0                No   \n",
       "16       ...                  2             0    0                No   \n",
       "17       ...                  2             0    0               Yes   \n",
       "18       ...                  2             0    0               Yes   \n",
       "19       ...                  2             0    0                No   \n",
       "20       ...                  1             0    0               Yes   \n",
       "21       ...                  3             0    0                No   \n",
       "22       ...                  1             0    0               Yes   \n",
       "23       ...                  2             0    0                No   \n",
       "24       ...                  3             0    0               Yes   \n",
       "25       ...                  5             0    0                No   \n",
       "26       ...                  0             0    0                No   \n",
       "27       ...                  1             0    0               Yes   \n",
       "28       ...                  2             0    1                No   \n",
       "29       ...                  1             0    0               Yes   \n",
       "..       ...                ...           ...  ...               ...   \n",
       "98       ...                  0             0    0               Yes   \n",
       "99       ...                  1             0    0                No   \n",
       "100      ...                  1             0    0                No   \n",
       "101      ...                  2             0    0               Yes   \n",
       "102      ...                  0             0    0               Yes   \n",
       "103      ...                  1             0    0                No   \n",
       "104      ...                  2             0    0               Yes   \n",
       "105      ...                  4             0    0                No   \n",
       "106      ...                  0             0    0               Yes   \n",
       "107      ...                  1             0    0                No   \n",
       "108      ...                  1             0    0               Yes   \n",
       "109      ...                  2             0    1                No   \n",
       "110      ...                  6             0    0                No   \n",
       "111      ...                  2             0    0               Yes   \n",
       "112      ...                  2             0    0                No   \n",
       "113      ...                  2             0    0               Yes   \n",
       "114      ...                  2             0    0                No   \n",
       "115      ...                  2             0    0               Yes   \n",
       "116      ...                  2             0    0                No   \n",
       "117      ...                  1             0    0               Yes   \n",
       "118      ...                  1             0    0                No   \n",
       "119      ...                  4             0    0               Yes   \n",
       "120      ...                  2             0    0               Yes   \n",
       "121      ...                  3             0    0                No   \n",
       "122      ...                  2             0    0               Yes   \n",
       "123      ...                  1             0    0                No   \n",
       "124      ...                  1             0    0               Yes   \n",
       "125      ...                  2             0    0                No   \n",
       "126      ...                  2             0    0               Yes   \n",
       "127      ...                  1             0    0                No   \n",
       "\n",
       "     1st Goal           Round  PSO  Goals in PSO  Own goals  Own goal Time  \n",
       "0        12.0     Group Stage   No             0        NaN            NaN  \n",
       "1         NaN     Group Stage   No             0        NaN            NaN  \n",
       "2         NaN     Group Stage   No             0        NaN            NaN  \n",
       "3        89.0     Group Stage   No             0        NaN            NaN  \n",
       "4         NaN     Group Stage   No             0        1.0           90.0  \n",
       "5        90.0     Group Stage   No             0        NaN            NaN  \n",
       "6         4.0     Group Stage   No             0        NaN            NaN  \n",
       "7        24.0     Group Stage   No             0        NaN            NaN  \n",
       "8        58.0     Group Stage   No             0        NaN            NaN  \n",
       "9        62.0     Group Stage   No             0        1.0           81.0  \n",
       "10       19.0     Group Stage   No             0        NaN            NaN  \n",
       "11       23.0     Group Stage   No             0        NaN            NaN  \n",
       "12        NaN     Group Stage   No             0        NaN            NaN  \n",
       "13       59.0     Group Stage   No             0        NaN            NaN  \n",
       "14       32.0     Group Stage   No             0        NaN            NaN  \n",
       "15        NaN     Group Stage   No             0        1.0           32.0  \n",
       "16        NaN     Group Stage   No             0        NaN            NaN  \n",
       "17       56.0     Group Stage   No             0        NaN            NaN  \n",
       "18        NaN     Group Stage   No             0        NaN            NaN  \n",
       "19       35.0     Group Stage   No             0        NaN            NaN  \n",
       "20       20.0     Group Stage   No             0        NaN            NaN  \n",
       "21       50.0     Group Stage   No             0        NaN            NaN  \n",
       "22       65.0     Group Stage   No             0        NaN            NaN  \n",
       "23        NaN     Group Stage   No             0        NaN            NaN  \n",
       "24       47.0     Group Stage   No             0        NaN            NaN  \n",
       "25        NaN     Group Stage   No             0        NaN            NaN  \n",
       "26       11.0     Group Stage   No             0        NaN            NaN  \n",
       "27       35.0     Group Stage   No             0        NaN            NaN  \n",
       "28       39.0     Group Stage   No             0        NaN            NaN  \n",
       "29        6.0     Group Stage   No             0        NaN            NaN  \n",
       "..        ...             ...  ...           ...        ...            ...  \n",
       "98        7.0     Round of 16   No             0        NaN            NaN  \n",
       "99       55.0     Round of 16   No             0        NaN            NaN  \n",
       "100      12.0     Round of 16  Yes             3        NaN            NaN  \n",
       "101      41.0     Round of 16  Yes             4        1.0           12.0  \n",
       "102       4.0     Round of 16  Yes             3        NaN            NaN  \n",
       "103       1.0     Round of 16  Yes             2        NaN            NaN  \n",
       "104      51.0     Round of 16   No             0        NaN            NaN  \n",
       "105       NaN     Round of 16   No             0        NaN            NaN  \n",
       "106      69.0     Round of 16   No             0        NaN            NaN  \n",
       "107      48.0     Round of 16   No             0        NaN            NaN  \n",
       "108      66.0     Round of 16   No             0        NaN            NaN  \n",
       "109       NaN     Round of 16   No             0        NaN            NaN  \n",
       "110      90.0     Round of 16  Yes             3        NaN            NaN  \n",
       "111      57.0     Round of 16  Yes             4        NaN            NaN  \n",
       "112       NaN  Quarter Finals   No             0        NaN            NaN  \n",
       "113      40.0  Quarter Finals   No             0        NaN            NaN  \n",
       "114       NaN  Quarter Finals   No             0        1.0           13.0  \n",
       "115      13.0  Quarter Finals   No             0        NaN            NaN  \n",
       "116       NaN  Quarter Finals   No             0        NaN            NaN  \n",
       "117      30.0  Quarter Finals   No             0        NaN            NaN  \n",
       "118      31.0  Quarter Finals  Yes             3        NaN            NaN  \n",
       "119      39.0  Quarter Finals  Yes             4        NaN            NaN  \n",
       "120      51.0    Semi- Finals   No             0        NaN            NaN  \n",
       "121       NaN    Semi- Finals   No             0        NaN            NaN  \n",
       "122      68.0    Semi- Finals   No             0        NaN            NaN  \n",
       "123       5.0    Semi- Finals   No             0        NaN            NaN  \n",
       "124       4.0       3rd Place   No             0        NaN            NaN  \n",
       "125       NaN       3rd Place   No             0        NaN            NaN  \n",
       "126      18.0           Final   No             0        1.0           18.0  \n",
       "127      28.0           Final   No             0        NaN            NaN  \n",
       "\n",
       "[128 rows x 27 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/fifa-2018-match-statistics/FIFA 2018 Statistics.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['14-06-2018', '15-06-2018', '16-06-2018', '17-06-2018',\n",
       "       '18-06-2018', '19-06-2018', '20-06-2018', '21-06-2018',\n",
       "       '22-06-2018', '23-06-2018', '24-06-2018', '25-06-2018',\n",
       "       '26-06-2018', '27-06-2018', '28-06-2018', '30-06-2018',\n",
       "       '01-07-2018', '02-07-2018', '03-07-2018', '06-07-2018',\n",
       "       '07-07-2018', '10-07-2018', '11-07-2018', '14-07-2018',\n",
       "       '15-07-2018'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date ['14-06-2018' '15-06-2018' '16-06-2018' '17-06-2018' '18-06-2018'\n",
      " '19-06-2018' '20-06-2018' '21-06-2018' '22-06-2018' '23-06-2018'\n",
      " '24-06-2018' '25-06-2018' '26-06-2018' '27-06-2018' '28-06-2018'\n",
      " '30-06-2018' '01-07-2018' '02-07-2018' '03-07-2018' '06-07-2018'\n",
      " '07-07-2018' '10-07-2018' '11-07-2018' '14-07-2018' '15-07-2018']\n",
      "Team ['Russia' 'Saudi Arabia' 'Egypt' 'Uruguay' 'Morocco' 'Iran' 'Portugal'\n",
      " 'Spain' 'France' 'Australia' 'Argentina' 'Iceland' 'Peru' 'Denmark'\n",
      " 'Croatia' 'Nigeria' 'Costa Rica' 'Serbia' 'Germany' 'Mexico' 'Brazil'\n",
      " 'Switzerland' 'Sweden' 'Korea Republic' 'Belgium' 'Panama' 'Tunisia'\n",
      " 'England' 'Colombia' 'Japan' 'Poland' 'Senegal']\n",
      "Opponent ['Saudi Arabia' 'Russia' 'Uruguay' 'Egypt' 'Iran' 'Morocco' 'Spain'\n",
      " 'Portugal' 'Australia' 'France' 'Iceland' 'Argentina' 'Denmark' 'Peru'\n",
      " 'Nigeria' 'Croatia' 'Serbia' 'Costa Rica' 'Mexico' 'Germany'\n",
      " 'Switzerland' 'Brazil' 'Korea Republic' 'Sweden' 'Panama' 'Belgium'\n",
      " 'England' 'Tunisia' 'Japan' 'Colombia' 'Senegal' 'Poland']\n",
      "Goal Scored [5 0 1 3 2 6 4]\n",
      "Ball Possession % [40 60 43 57 64 36 39 61 51 49 72 28 52 48 54 46 50 41 59 47 53 30 70 44\n",
      " 56 58 42 66 34 71 29 45 55 68 32 38 62 65 35 75 25 37 63]\n",
      "Attempts [13  6  8 14 12  4 26  9 18 10 11 25 20 15  5 17 16 23  7  3 22 19 21 24]\n",
      "On-Target [ 7  0  3  4  2  5  1  6  9 12 10  8]\n",
      "Off-Target [ 3  6  5  2  4  9  7  1  8 10 11]\n",
      "Blocked [ 3  2  4  1 10  5  7  0  6  8  9]\n",
      "Corners [ 6  2  0  5  4  1 10  3  7  8  9 11]\n",
      "Offsides [3 1 0 5 2 4]\n",
      "Free Kicks [11 25  7 13 14 22 19 16 15 10 21 17 18 23 24 20  5  8 26  6 12]\n",
      "Saves [0 2 3 1 4 7 6 9 5 8]\n",
      "Pass Accuracy % [78 86 87 93 85 92 67 82 84 83 88 79 89 91 81 76 77 69 80 90 73 75 94 72\n",
      " 74]\n",
      "Passes [ 306  511  395  589  433  194  366  727  484  390  718  189  394  342\n",
      "  462  388  428  392  595  281  521  436  417  351  544  317  326  492\n",
      "  352  565  552  328  380  438  387  466  590  219  805  458  520  405\n",
      "  532  505  372  732  271  473  291  309  547  468  477  346  485  699\n",
      "  213  593  398  449  338  424  514  355  655  357  762  247  226  619\n",
      "  305  669  555  418  244  324  524  237  719  487  212  467  631  594\n",
      "  348  557  431  284  626  556  269  583 1137  539  621  453  599  516\n",
      "  571  322  370  379  525  399  753  629  622  479  510  698]\n",
      "Distance Covered (Kms) [118 105 112 111 101 100 102 103 104 110 107 109 106 108  93 115 114 116\n",
      "  99  97  89  98  95  83  80  96 137 146 132 135  92 136 143 148 139]\n",
      "Fouls Committed [22 10 12  6 14 16 19 15 18 20 23 17  8  9 11 13  7  5 24 21 25]\n",
      "Yellow Card [0 2 1 3 5 4 6]\n",
      "Yellow & Red [0 1]\n",
      "Red [0 1]\n",
      "Man of the Match ['Yes' 'No']\n",
      "1st Goal [12. nan 89. 90.  4. 24. 58. 62. 19. 23. 59. 32. 56. 35. 20. 50. 65. 47.\n",
      " 11. 39.  6. 37. 60. 54.  7. 38. 34. 53. 49.  5. 52. 18. 26. 48.  8. 78.\n",
      " 40. 10. 45. 22. 14. 51. 76. 36. 31. 74. 33. 13. 41. 55.  1. 69. 66. 57.\n",
      " 30. 68. 28.]\n",
      "Round ['Group Stage' 'Round of 16' 'Quarter Finals' 'Semi- Finals' '3rd Place'\n",
      " 'Final']\n",
      "PSO ['No' 'Yes']\n",
      "Goals in PSO [0 3 4 2]\n",
      "Own goals [nan  1.]\n",
      "Own goal Time [nan 90. 81. 32. 37. 47. 23. 74. 33. 12. 13. 18.]\n"
     ]
    }
   ],
   "source": [
    "# print unique values per column\n",
    "for c in df.columns:\n",
    "    print(c, df[c].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoders = dict() # store our encoders for use during prediction\n",
    "\n",
    "for c in ['Team', 'Opponent', 'Man of the Match', 'Round', 'PSO']:\n",
    "    encoders[c] = LabelEncoder()\n",
    "    df[c] = encoders[c].fit_transform(df[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Argentina', 'Australia', 'Belgium', 'Brazil', 'Colombia',\n",
       "       'Costa Rica', 'Croatia', 'Denmark', 'Egypt', 'England', 'France',\n",
       "       'Germany', 'Iceland', 'Iran', 'Japan', 'Korea Republic', 'Mexico',\n",
       "       'Morocco', 'Nigeria', 'Panama', 'Peru', 'Poland', 'Portugal',\n",
       "       'Russia', 'Saudi Arabia', 'Senegal', 'Serbia', 'Spain', 'Sweden',\n",
       "       'Switzerland', 'Tunisia', 'Uruguay'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders['Team'].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\issohl\\AppData\\Local\\Continuum\\miniconda3\\envs\\mldds01\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Team name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Egypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>Uruguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Morocco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>Iran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22</td>\n",
       "      <td>Portugal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>Argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Iceland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>Denmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>Croatia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>Costa Rica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26</td>\n",
       "      <td>Serbia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16</td>\n",
       "      <td>Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>29</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>28</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15</td>\n",
       "      <td>Korea Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>19</td>\n",
       "      <td>Panama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30</td>\n",
       "      <td>Tunisia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>Colombia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>31</td>\n",
       "      <td>Uruguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>22</td>\n",
       "      <td>Portugal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>27</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>23</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>6</td>\n",
       "      <td>Croatia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>7</td>\n",
       "      <td>Denmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>3</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>16</td>\n",
       "      <td>Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>14</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>28</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>29</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>4</td>\n",
       "      <td>Colombia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>9</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>31</td>\n",
       "      <td>Uruguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>10</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>3</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>28</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>9</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>23</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6</td>\n",
       "      <td>Croatia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>10</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>6</td>\n",
       "      <td>Croatia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>9</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>9</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>10</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6</td>\n",
       "      <td>Croatia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Team       Team name\n",
       "0      23          Russia\n",
       "1      24    Saudi Arabia\n",
       "2       8           Egypt\n",
       "3      31         Uruguay\n",
       "4      17         Morocco\n",
       "5      13            Iran\n",
       "6      22        Portugal\n",
       "7      27           Spain\n",
       "8      10          France\n",
       "9       1       Australia\n",
       "10      0       Argentina\n",
       "11     12         Iceland\n",
       "12     20            Peru\n",
       "13      7         Denmark\n",
       "14      6         Croatia\n",
       "15     18         Nigeria\n",
       "16      5      Costa Rica\n",
       "17     26          Serbia\n",
       "18     11         Germany\n",
       "19     16          Mexico\n",
       "20      3          Brazil\n",
       "21     29     Switzerland\n",
       "22     28          Sweden\n",
       "23     15  Korea Republic\n",
       "24      2         Belgium\n",
       "25     19          Panama\n",
       "26     30         Tunisia\n",
       "27      9         England\n",
       "28      4        Colombia\n",
       "29     14           Japan\n",
       "..    ...             ...\n",
       "98     31         Uruguay\n",
       "99     22        Portugal\n",
       "100    27           Spain\n",
       "101    23          Russia\n",
       "102     6         Croatia\n",
       "103     7         Denmark\n",
       "104     3          Brazil\n",
       "105    16          Mexico\n",
       "106     2         Belgium\n",
       "107    14           Japan\n",
       "108    28          Sweden\n",
       "109    29     Switzerland\n",
       "110     4        Colombia\n",
       "111     9         England\n",
       "112    31         Uruguay\n",
       "113    10          France\n",
       "114     3          Brazil\n",
       "115     2         Belgium\n",
       "116    28          Sweden\n",
       "117     9         England\n",
       "118    23          Russia\n",
       "119     6         Croatia\n",
       "120    10          France\n",
       "121     2         Belgium\n",
       "122     6         Croatia\n",
       "123     9         England\n",
       "124     2         Belgium\n",
       "125     9         England\n",
       "126    10          France\n",
       "127     6         Croatia\n",
       "\n",
       "[128 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams = encoders['Team'].inverse_transform(df['Team']) # convert back\n",
    "\n",
    "# for showing\n",
    "df2 = pd.DataFrame(df['Team'])\n",
    "df2['Team name'] = teams\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date ['14-06-2018' '15-06-2018' '16-06-2018' '17-06-2018' '18-06-2018'\n",
      " '19-06-2018' '20-06-2018' '21-06-2018' '22-06-2018' '23-06-2018'\n",
      " '24-06-2018' '25-06-2018' '26-06-2018' '27-06-2018' '28-06-2018'\n",
      " '30-06-2018' '01-07-2018' '02-07-2018' '03-07-2018' '06-07-2018'\n",
      " '07-07-2018' '10-07-2018' '11-07-2018' '14-07-2018' '15-07-2018']\n",
      "Team [23 24  8 31 17 13 22 27 10  1  0 12 20  7  6 18  5 26 11 16  3 29 28 15\n",
      "  2 19 30  9  4 14 21 25]\n",
      "Opponent [24 23 31  8 13 17 27 22  1 10 12  0  7 20 18  6 26  5 16 11 29  3 15 28\n",
      " 19  2  9 30 14  4 25 21]\n",
      "Goal Scored [5 0 1 3 2 6 4]\n",
      "Ball Possession % [40 60 43 57 64 36 39 61 51 49 72 28 52 48 54 46 50 41 59 47 53 30 70 44\n",
      " 56 58 42 66 34 71 29 45 55 68 32 38 62 65 35 75 25 37 63]\n",
      "Attempts [13  6  8 14 12  4 26  9 18 10 11 25 20 15  5 17 16 23  7  3 22 19 21 24]\n",
      "On-Target [ 7  0  3  4  2  5  1  6  9 12 10  8]\n",
      "Off-Target [ 3  6  5  2  4  9  7  1  8 10 11]\n",
      "Blocked [ 3  2  4  1 10  5  7  0  6  8  9]\n",
      "Corners [ 6  2  0  5  4  1 10  3  7  8  9 11]\n",
      "Offsides [3 1 0 5 2 4]\n",
      "Free Kicks [11 25  7 13 14 22 19 16 15 10 21 17 18 23 24 20  5  8 26  6 12]\n",
      "Saves [0 2 3 1 4 7 6 9 5 8]\n",
      "Pass Accuracy % [78 86 87 93 85 92 67 82 84 83 88 79 89 91 81 76 77 69 80 90 73 75 94 72\n",
      " 74]\n",
      "Passes [ 306  511  395  589  433  194  366  727  484  390  718  189  394  342\n",
      "  462  388  428  392  595  281  521  436  417  351  544  317  326  492\n",
      "  352  565  552  328  380  438  387  466  590  219  805  458  520  405\n",
      "  532  505  372  732  271  473  291  309  547  468  477  346  485  699\n",
      "  213  593  398  449  338  424  514  355  655  357  762  247  226  619\n",
      "  305  669  555  418  244  324  524  237  719  487  212  467  631  594\n",
      "  348  557  431  284  626  556  269  583 1137  539  621  453  599  516\n",
      "  571  322  370  379  525  399  753  629  622  479  510  698]\n",
      "Distance Covered (Kms) [118 105 112 111 101 100 102 103 104 110 107 109 106 108  93 115 114 116\n",
      "  99  97  89  98  95  83  80  96 137 146 132 135  92 136 143 148 139]\n",
      "Fouls Committed [22 10 12  6 14 16 19 15 18 20 23 17  8  9 11 13  7  5 24 21 25]\n",
      "Yellow Card [0 2 1 3 5 4 6]\n",
      "Yellow & Red [0 1]\n",
      "Red [0 1]\n",
      "Man of the Match [1 0]\n",
      "1st Goal [12. nan 89. 90.  4. 24. 58. 62. 19. 23. 59. 32. 56. 35. 20. 50. 65. 47.\n",
      " 11. 39.  6. 37. 60. 54.  7. 38. 34. 53. 49.  5. 52. 18. 26. 48.  8. 78.\n",
      " 40. 10. 45. 22. 14. 51. 76. 36. 31. 74. 33. 13. 41. 55.  1. 69. 66. 57.\n",
      " 30. 68. 28.]\n",
      "Round [2 4 3 5 0 1]\n",
      "PSO [0 1]\n",
      "Goals in PSO [0 3 4 2]\n",
      "Own goals [nan  1.]\n",
      "Own goal Time [nan 90. 81. 32. 37. 47. 23. 74. 33. 12. 13. 18.]\n"
     ]
    }
   ],
   "source": [
    "# print unique values per column\n",
    "for c in df.columns:\n",
    "    print(c, df[c].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To fix these:\n",
    "# 1st Goal [12. nan 89. 90.  4. 24. 58. 62. 19. ...\n",
    "# Own goals [nan  1.]\n",
    "# Own goal Time [nan 90. 81. 32. 37. 47. 23. 74. 33. 12. 13. 18.]\n",
    "\n",
    "df['1st Goal'].fillna(-1, inplace=True)\n",
    "\n",
    "df['Own goals'].fillna(0, inplace=True)\n",
    "\n",
    "df['Own goal Time'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st Goal [12. -1. 89. 90.  4. 24. 58. 62. 19. 23. 59. 32. 56. 35. 20. 50. 65. 47.\n",
      " 11. 39.  6. 37. 60. 54.  7. 38. 34. 53. 49.  5. 52. 18. 26. 48.  8. 78.\n",
      " 40. 10. 45. 22. 14. 51. 76. 36. 31. 74. 33. 13. 41. 55.  1. 69. 66. 57.\n",
      " 30. 68. 28.]\n"
     ]
    }
   ],
   "source": [
    "print('1st Goal', df['1st Goal'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before (128, 25)\n",
      "After (128, 5)\n",
      "Support [False False  True False  True  True False False  True False False False\n",
      " False False False False False False False  True False False False False\n",
      " False]\n",
      "Index(['Goal Scored', 'Attempts', 'On-Target', 'Corners', '1st Goal'], dtype='object')\n",
      "[1.89214397e-01 1.89214397e-01 4.72400405e+01 1.55444988e+00\n",
      " 4.04786120e+00 1.16872762e+01 3.01939641e+00 4.83334754e-02\n",
      " 3.89426379e+00 8.71369295e-02 1.82643417e+00 1.49652482e-01\n",
      " 1.53500932e+00 1.30953108e+00 2.97080010e-02 2.13381496e+00\n",
      " 2.81914513e+00 0.00000000e+00 2.03225806e+00 1.77133646e+01\n",
      " 0.00000000e+00 0.00000000e+00 1.90692395e-01 1.46511628e+00\n",
      " 1.82040582e+00]\n"
     ]
    }
   ],
   "source": [
    "# Apply feature selection using statistics\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "\n",
    "y = df['Man of the Match']\n",
    "X_all = df.loc[:, (df.columns != 'Man of the Match') & (df.columns != 'Date')]\n",
    "\n",
    "# let's say, we want 5 features\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "\n",
    "X_kbest = selector.fit_transform(X_all, y)\n",
    "\n",
    "print('Before', X_all.shape)\n",
    "print('After', X_kbest.shape)\n",
    "\n",
    "# which columns are selected?\n",
    "print('Support', selector.get_support())\n",
    "print(X_all.columns[selector.get_support()])\n",
    "print(selector.scores_) # ANOVA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Goal Scored', 'Attempts', 'On-Target', 'Corners', '1st Goal'], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.columns[selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_kbest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio 0.7202431217062457\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# scale the 5 features\n",
    "X_scaled = StandardScaler().fit_transform(X_kbest)\n",
    "\n",
    "# plotting in 2D to visualize\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X_scaled)\n",
    "print('Explained variance ratio', np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_2d[y==0, 0], X_2d[y==0, 1], label='no')\n",
    "ax.scatter(X_2d[y==1, 0], X_2d[y==1, 1], label='yes')\n",
    "ax.set(title='Man of the Match: PCA plot with 5-best features')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Training on 5 best features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_kbest, y, random_state=42)\n",
    "\n",
    "# Actual scaler for training and prediction\n",
    "X_scaler = StandardScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.71      0.59        14\n",
      "          1       0.67      0.44      0.53        18\n",
      "\n",
      "avg / total       0.59      0.56      0.56        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# No ensemble\n",
    "sgd = SGDClassifier(max_iter=1000, tol=1e-3) # 0.20 defaults (forward compat)\n",
    "sgd.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Accuracy', sgd.score(X_test_scaled, y_test))\n",
    "\n",
    "pred = sgd.predict(X_test_scaled)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.71875\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.79      0.71        14\n",
      "          1       0.80      0.67      0.73        18\n",
      "\n",
      "avg / total       0.73      0.72      0.72        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# bagging\n",
    "bag = BaggingClassifier(SGDClassifier(max_iter=1000,\n",
    "                                      tol=1e-3), # classifier\n",
    "                        n_estimators=100, # number of estimators\n",
    "                        max_samples=.5) # randomly train on 50% of training\n",
    "                                        # set\n",
    "bag.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Accuracy', bag.score(X_test_scaled, y_test))\n",
    "\n",
    "pred = bag.predict(X_test_scaled)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=978717844,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1. 11.  2.  7. 59.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 2. 20.  5.  7. 52.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1198921154,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1418756294,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 1. 14.  4.  5. 45.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=4530895,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 2. 11.  2.  6. 32.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1750099943,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=2003199630,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2. 11.  2.  6. 32.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=312958258,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1786616261,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1553126685,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1672470849,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1720830734,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 0. 14.  2.  5. -1.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1705536239,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 3. 15.  6.  9. 47.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=2048160103,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 3. 24.  8. 10. 69.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1307711086,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1. 15.  4.  6. 65.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=2013183244,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=2134316062,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 3. 15.  6.  9. 47.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=97370763,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1. 16.  2.  7. 57.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 3. 24.  8. 10. 69.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 1.  9.  4.  0. 33.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1147331154,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1.  8.  1.  2. 22.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1233596420,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1.  8.  1.  2. 22.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=915985535,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=222492994,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 20.  5.  7. 52.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=300894844,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 3. 15.  6.  9. 47.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2. 20.  5.  7. 52.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=781740219,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1. 11.  2.  7. 59.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1472150236,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1. 16.  2.  7. 57.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 2. 11.  2.  6. 32.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=820692521,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 2.  8.  4.  5. 14.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 20.  5.  7. 52.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=385190768,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1.  8.  1.  2. 22.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=406397540,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 1. 14.  4.  5. 45.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=587352054,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=2015918934,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 3. 15.  6.  9. 47.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 2. 20.  5.  7. 52.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1077312083,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 3. 15.  6.  9. 47.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=634515272,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1.  8.  1.  2. 22.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1021037212,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1.  8.  1.  2. 22.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=291550814,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1. 16.  2.  7. 57.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=328833457,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 3. 15.  6.  9. 47.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=128643870,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 3. 15.  6.  9. 47.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=739777632,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1810051880,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=577420860,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=2032807386,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1.  8.  1.  2. 22.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1504728162,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 3. 15.  6.  9. 47.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=2052436736,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=280086339,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 14.  4.  5. 45.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1248794647,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 2.  8.  4.  5. 14.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1182339149,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1316915940,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=148908185,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1.  9.  4.  0. 33.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=61407515,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=103297410,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1.  9.  4.  0. 33.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=509099258,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=491659338,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 1. 20.  4.  7. 20.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1749140645,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 2.  8.  4.  5. 14.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=695877673,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=753749677,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 3. 15.  6.  9. 47.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 14.  4.  5. 45.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=691098489,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1307260051,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1464820908,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 0. 14.  2.  5. -1.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=539315650,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1.  8.  1.  2. 22.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=2105029995,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. 16.  2.  7. 57.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1855647627,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1.  9.  4.  0. 33.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1023295728,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1.  8.  1.  2. 22.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=707496811,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=612875838,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1.  9.  4.  0. 33.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1549361285,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 20.  5.  7. 52.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=992150906,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1.  8.  1.  2. 22.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1.  9.  4.  0. 33.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1882895604,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 20.  5.  7. 52.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=210622538,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 0.  3.  1.  2. -1.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 2. 20.  5.  7. 52.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1495204452,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1.  8.  1.  2. 22.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1.  9.  4.  0. 33.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1363730822,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=672035654,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=268412181,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1. 15.  4.  6. 65.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1.  9.  4.  0. 33.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=15055752,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1. 16.  2.  7. 57.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=732125629,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 0. 14.  2.  5. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1201049925,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 3. 15.  6.  9. 47.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 3. 24.  8. 10. 69.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=2123210968,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 3. 15.  6.  9. 47.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1502820327,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1. 16.  2.  7. 57.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 11.  2.  6. 32.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=911990015,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 3. 24.  8. 10. 69.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1142318327,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1.  9.  4.  0. 33.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1735407595,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 1.  9.  4.  0. 33.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=765734316,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. 14.  2.  5. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=429757318,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 19.  3.  7. -1.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1800109668,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 2. 20.  5.  7. 52.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=911282216,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 3. 15.  6.  9. 47.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=26341155,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1.  8.  1.  2. 22.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1976707554,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=413722248,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1.  8.  1.  2. 22.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2. 20.  5.  7. 52.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=487939389,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1.  8.  1.  2. 22.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1433664954,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1.  8.  1.  2. 22.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 1.  9.  4.  0. 33.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=275163607,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=195621165,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 3. 15.  6.  9. 47.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 1. 14.  4.  5. 45.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1859303726,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 1.  9.  4.  0. 33.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1552703201,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 2. 11.  2.  6. 32.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1518157443,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1. 16.  2.  7. 57.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2.  7.  3.  2. 34.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=887547823,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 0.  6.  0.  2. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 1.  9.  4.  0. 33.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=424963168,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 0.  5.  0.  2. -1.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=12957324,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 3. 15.  6.  9. 47.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 0.  8.  3.  4. -1.]\n",
      " [ 2. 14.  6.  6.  6.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1087565305,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 1. 15.  4.  6. 65.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 2.  8.  3.  4. 13.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 2.  4.  3.  3. 18.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 1. 14.  4.  5. 45.]\n",
      " [ 2. 20.  5.  7. 52.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=791032259,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1.  8.  1.  2. 22.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 2. 13.  6.  9. 36.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1.  9.  3.  3. 51.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 10.  3.  4. 56.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 1. 17.  6.  7. 90.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 14.  7.  5. 11.]\n",
      " [ 2. 12.  4.  4.  4.]\n",
      " [ 2. 13.  2.  5. 53.]\n",
      " [ 1.  6.  1.  5. 41.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 3. 11.  3.  7. 59.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 20.  5.  7. 52.]\n",
      " [ 1. 22.  7.  5.  4.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1972358003,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 3. 15.  6.  9. 47.]\n",
      " [ 1. 16.  2.  7. 57.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 1. 15.  4.  2. 51.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 0.  9.  2.  7. -1.]\n",
      " [ 2. 22.  7.  7. 45.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 1. 17.  3.  6. 54.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 1. 10.  2.  5.  4.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 11.  4.  4. -1.]\n",
      " [ 1. 10.  3.  7. 59.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 0.  5.  1.  4. -1.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 1. 14.  4.  2. 90.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 1. 14.  5.  5. 38.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 0.  8.  3.  1. -1.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1.  6.  2.  2. 50.]\n",
      " [ 0.  8.  3.  0. -1.]\n",
      " [ 0.  5.  0.  5. -1.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 0. 14.  2.  8. -1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 1.  9.  4.  0. 33.]\n",
      " [ 2. 20.  5.  7. 52.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=217843119,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 0. 14.  2.  5. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  9.  3.  5. -1.]\n",
      " [ 1.  4.  1.  1. 62.]\n",
      " [ 0.  6.  2.  3. -1.]\n",
      " [ 1.  4.  2.  3. 74.]\n",
      " [ 2. 15.  5.  2. 18.]\n",
      " [ 1.  8.  2.  2. 90.]\n",
      " [ 2. 16.  4.  7. 19.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 16.  4.  7. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 2. 22.  7.  8. 68.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 1. 12.  3.  3. 66.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 2. 15.  7.  6. 51.]\n",
      " [ 1. 14.  4.  5. 89.]\n",
      " [ 1. 25.  9.  6. 12.]\n",
      " [ 3.  8.  3.  4.  4.]\n",
      " [ 3. 13.  5.  3. 50.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 2. 11.  4.  6. 48.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 0. 19.  3.  7. -1.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 1. 20.  4.  7. 20.]\n",
      " [ 3. 24.  8. 10. 69.]\n",
      " [ 2. 11.  2.  6. 32.]]\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=798209866,\n",
      "       shuffle=True, tol=0.001, verbose=0, warm_start=False)\n",
      "[[ 4.  8.  6.  2. 18.]\n",
      " [ 1. 11.  2.  7. 59.]\n",
      " [ 2.  8.  4.  5. 14.]\n",
      " [ 1. 15.  4.  6. 65.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0.  3.  1.  2. -1.]\n",
      " [ 1. 10.  4.  3. 37.]\n",
      " [ 1. 13.  1.  4. 47.]\n",
      " [ 1.  8.  3.  3. 39.]\n",
      " [ 3.  9.  4.  4. 41.]\n",
      " [ 0. 11.  4.  2. -1.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 3. 12.  5.  5. 24.]\n",
      " [ 0. 10.  2.  3. -1.]\n",
      " [ 2. 12.  5.  5. 58.]\n",
      " [ 2. 17.  3.  8. 39.]\n",
      " [ 1. 12.  3.  3.  5.]\n",
      " [ 2. 12.  2.  6. 30.]\n",
      " [ 2. 23.  9. 10. 90.]\n",
      " [ 1. 11.  1.  4.  5.]\n",
      " [ 6. 12.  7.  3.  8.]\n",
      " [ 2. 16.  4.  6. 49.]\n",
      " [ 0. 10.  3.  5. -1.]\n",
      " [ 0. 18.  4. 11. -1.]\n",
      " [ 1.  8.  6.  3. 32.]\n",
      " [ 1. 19.  5.  4. 51.]\n",
      " [ 1.  8.  2.  2. 78.]\n",
      " [ 3. 13.  3.  5. 40.]\n",
      " [ 1. 26.  9.  8. -1.]\n",
      " [ 5. 23. 12.  5.  6.]\n",
      " [ 1. 15.  3.  4.  1.]\n",
      " [ 1. 20.  5. 10. 55.]\n",
      " [ 2. 14.  6.  5. 56.]\n",
      " [ 0.  7.  3.  1. -1.]\n",
      " [ 2. 12.  3.  6. 31.]\n",
      " [ 2. 15.  3.  6. 28.]\n",
      " [ 2.  7.  3.  2. 34.]\n",
      " [ 1. 14.  4.  5. 45.]]\n"
     ]
    }
   ],
   "source": [
    "# which sample is used to train which model\n",
    "for i in range(len(bag.estimators_samples_)):\n",
    "    print(bag.estimators_[i])\n",
    "    print(X_train[bag.estimators_samples_[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.78125\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.86      0.77        14\n",
      "          1       0.87      0.72      0.79        18\n",
      "\n",
      "avg / total       0.80      0.78      0.78        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Boosting\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(SGDClassifier(max_iter=1000,\n",
    "                                      tol=1e-3), # classifier\n",
    "                        n_estimators=100,  # number of estimators\n",
    "                        algorithm='SAMME')\n",
    "\n",
    "ada.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Accuracy', ada.score(X_test_scaled, y_test))\n",
    "\n",
    "pred = ada.predict(X_test_scaled)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x257a88fc748>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ada.estimator_weights_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
       "        n_jobs=1, penalty='l2', power_t=0.5, random_state=158078270,\n",
       "        shuffle=True, tol=0.001, verbose=0, warm_start=False),\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
       "        n_jobs=1, penalty='l2', power_t=0.5, random_state=1154232894,\n",
       "        shuffle=True, tol=0.001, verbose=0, warm_start=False),\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
       "        n_jobs=1, penalty='l2', power_t=0.5, random_state=1759956152,\n",
       "        shuffle=True, tol=0.001, verbose=0, warm_start=False)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.estimators_\n",
    "# ada.estimator_errors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71875\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.86      0.73        14\n",
      "          1       0.85      0.61      0.71        18\n",
      "\n",
      "avg / total       0.75      0.72      0.72        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\issohl\\AppData\\Local\\Continuum\\miniconda3\\envs\\mldds01\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\issohl\\AppData\\Local\\Continuum\\miniconda3\\envs\\mldds01\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Voting classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Soft voting with weights\n",
    "clf1 = DecisionTreeClassifier(max_depth=4)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)],\n",
    "    voting='soft', weights=[2,1,2]\n",
    ")\n",
    "\n",
    "eclf = eclf.fit(X_train_scaled, y_train)\n",
    "print(eclf.score(X_test_scaled, y_test))\n",
    "\n",
    "pred = eclf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'),\n",
       " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "            weights='uniform'),\n",
       " SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "   max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf.score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
