{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Topics\n",
    "\n",
    "- Motivation\n",
    "- Process\n",
    "- Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "- Lots of data, time, resources needed to train and tune a neural network from scratch\n",
    "\n",
    "- Cheaper, faster way of adapting a neural network by exploiting their generalization properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examples\n",
    "\n",
    "Transfer learning is often featured in the \"train your own AI model\" services:\n",
    "\n",
    "- https://cloud.google.com/blog/big-data/2018/03/automl-vision-in-action-from-ramen-to-branded-goods\n",
    "- https://azure.microsoft.com/en-us/services/cognitive-services/custom-vision-service/\n",
    "- https://github.com/awslabs/amazon-sagemaker-examples/tree/master/introduction_to_amazon_algorithms/imageclassification_caltech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural Network Layers: General to Specific \n",
    "\n",
    "- Bottom/first/earlier layers: general learners\n",
    " - Low-level notions of edges, visual shapes\n",
    "\n",
    "- Top/last/later layers: specific learners\n",
    "  - High-level features such as eyes, feathers\n",
    "  \n",
    "Note: the top/bottom notation is confusing, I'd avoid it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: VGG 16 Filters\n",
    "\n",
    "![vgg filters](assets/transfer/vgg16_filters_overview.jpg)\n",
    "\n",
    "https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![overview](assets/transfer/Transfer+Learning+Overview.jpg)\n",
    "\n",
    "(image: [Aghamirzaie & Salomon](http://slideplayer.com/slide/8370683/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Process\n",
    "\n",
    "1. Start with pre-trained network\n",
    "\n",
    "2. Partition network into:\n",
    " - Featurizers: identify which layers to keep\n",
    " - Classifiers: identify which layers to replace\n",
    "\n",
    "3. Re-train classifier layers with new data\n",
    "\n",
    "4. Unfreeze weights and fine-tune whole network with smaller learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Freezing and Fine-tuning\n",
    "\n",
    "![vgg 16 modified](assets/transfer/vgg16_modified.png)\n",
    "\n",
    "(image: http://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Which layers to re-train?\n",
    "\n",
    "- Depends on the domain\n",
    "- Start by re-training the last layers (last full-connected and last convolutional)\n",
    "  - work backwards if performance is not satisfactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "![transfer performance](assets/transfer/transfer_performance.png)\n",
    "\n",
    "(image: http://arxiv.org/abs/1411.1792)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When and how to fine-tune?\n",
    "\n",
    "Suppose we have model A, trained on dataset A\n",
    "Q: How do we apply transfer learning to dataset B to create model B?\n",
    "\n",
    "|Dataset size|Dataset similarity|Recommendation|\n",
    "|--|--|--|\n",
    "|Large|Very different|Train model B  from scratch, initialize weights from model A|\n",
    "|Large|Similar|OK to fine-tune (less likely to overfit)|\n",
    "|Small|Very different|Train classifier using the earlier layers (later layers won't help much)|\n",
    "|Small|Similar|Don't fine-tune (overfitting). Train a linear classifier|\n",
    "\n",
    "https://cs231n.github.io/transfer-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Rate\n",
    "\n",
    "- Training linear classifier: typical learning rate\n",
    "\n",
    "- Fine-tuning: use smaller learning rate to avoid distorting the (already decent) weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Workshop: Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "livereveal": {
    "autolaunch": false,
    "overlay": "<div class='logo'><img src='assets/Stackup_Logo_Small.png' width='90%'/></div>"
   },
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
