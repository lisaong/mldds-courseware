{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My first machine learning model\n",
    "\n",
    "![toy](assets/my-first/toy.jpg)\n",
    "\n",
    "(image: flickr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics\n",
    "- The end-to-end process \n",
    "- A simple linear regression model\n",
    "- Data Preparation\n",
    "- Training\n",
    "- Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop\n",
    "\n",
    "In this workshop, we will walk through creating and training a simple machine learning model from scratch.\n",
    "\n",
    "Through out the course, we'll be repeating the tasks in this process for different machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science Process\n",
    "\n",
    "![workflow](assets/intro/ds.png)\n",
    "\n",
    "(image: szilard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What we will cover today\n",
    "\n",
    "1. Data transformation and cleaning\n",
    "2. Feature selection\n",
    "3. Model creation and training\n",
    "4. Model validation\n",
    "5. Undestanding results and iterating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Task\n",
    "\n",
    "For our first machine learning problem, we will try to predict Singapore's Foreign Reserves based on Gross Domestic Product (GDP).\n",
    "\n",
    "### Datasets\n",
    "1. Gross Domestic Product at Current Prices, Annual: https://data.gov.sg/dataset/income-components-of-gross-domestic-product-at-current-prices-annual\n",
    "2. Total Foreign Reserves: https://data.gov.sg/dataset/total-foreign-reserves\n",
    "\n",
    "\n",
    "- Download both datasets\n",
    "- Note their paths for use later, when we call `pandas.read_csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation: scikit-learn\n",
    "\n",
    "Install scikit-learn, a machine learning library that we'll use in this and subsequent modules.\n",
    "```\n",
    "conda install scikit-learn\n",
    "```\n",
    "\n",
    "More information about scikit-learn: http://scikit-learn.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Transformation and Cleaning\n",
    "\n",
    "The first step is to inspect the data. We are looking for a relationship between GDP and Foreign Reserves.\n",
    "\n",
    "First, we have the Annual Gross Domestic Product, which is our independent variable.\n",
    "\n",
    "Let's notate it as `x`, so the corresponding DataFrame will be `df_x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.read_csv('D:/tmp/income-components-of-gross-domestic-product-at-current-prices-annual/gross-domestic-product-at-current-market-prices-annual.csv',\n",
    "                parse_dates=['year'], index_col=0)\n",
    "df_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have the Annual Total Foreign Reserves, which is our **dependent** variable (we think it is dependent on X).\n",
    "\n",
    "Let's notate is as `y`, so the corresponding DataFrame will be `df_y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.read_csv('D:/tmp/total-foreign-reserves/total-foreign-reserves-annual.csv',\n",
    "                parse_dates=['year'], index_col=0)\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like `df_x` has a different date range than `df_y`. Let's print the ranges to confirm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time range of df_x:', df_x.index.values.min(), df_x.index.values.max())\n",
    "print('Time range of df_y:', df_y.index.values.min(), df_y.index.values.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the datasets\n",
    "\n",
    "Since we have two datasets, let's join them into a single DataFrame.\n",
    "\n",
    "We will do:\n",
    "- a left join of `df_y` onto `df_x`, and\n",
    "- drop any NaN values\n",
    "\n",
    "This will also take care of the different date ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_x.join(df_y).dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot to inspect possible relationships\n",
    "\n",
    "Let's also plot the relationship between X and Y.\n",
    "\n",
    "Between 2 or 3 variables, a scatter plot is useful to see if the (x, y) points lie on some sort of line or curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "df.plot(kind='scatter', x='value', y='total_foreign_reserve_sgd', ax=ax)\n",
    "\n",
    "ax.set(xlabel='Annual GDP S$ million',\n",
    "       ylabel='Annual Total Foreign Reserves S$ million')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with other columns as well, to explore the data further and observe other relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "df.plot(kind='scatter', x='value', y='imf_reserve_position', ax=ax) # less linear\n",
    "\n",
    "ax.set(xlabel='Annual GDP S$ million', ylabel='IMF Reserve Position S$ million')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature selection\n",
    "\n",
    "For this simple task, feature selection is straightforward. \n",
    "\n",
    "No further transformation is needed because:\n",
    "- The data is already in numerical format, and we've dropped missing values.\n",
    "- There's only one feature, so there no need to normalize the features by scaling or re-centering them.\n",
    "\n",
    "### Inputs\n",
    "\n",
    "|Feature|Description|Column name|Transformation before model input?|\n",
    "|--|--|--|\n",
    "|$x_1$|Annual GDP S$ million|value|None|\n",
    "\n",
    "### Outputs\n",
    "\n",
    "|Output|Description|Truth column|Transformation from model output?|\n",
    "|--|--|--|\n",
    "|$\\hat{y}$|Predicted Annual Foreign Reserves S\\$ million|$y$ = total_foreign_reserve_sgd|None|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's our resulting dataset after feature selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'x1': df.value.values, 'y': df.total_foreign_reserve_sgd.values}\n",
    "df_dataset = pd.DataFrame(data=data)\n",
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model creation and training\n",
    "\n",
    "In this section, we'll train a simple single-variable Linear Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "Textbook definition:\n",
    "- Linear regression takes a vector x ($x \\in \\Re$) as input, and predicts the value of a scalar y ($y \\in \\Re$) as output.\n",
    "- Let $\\hat{y}$ be the value that the model predicts, then:\n",
    "\n",
    "$$\\hat{y} = w^Tx,$$\n",
    "\n",
    "where\n",
    "- $w^Tx$ is known as the **linear function** of the input\n",
    "- $w \\in \\Re$ are the parameters or weights of that linear function\n",
    "\n",
    "(Reference: Deep Learning - Goodfellow, Bengio, Courville, MIT press, 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application to our problem\n",
    "\n",
    "This table summarizes how Linear Regression will be applied to our machine learning problem.\n",
    "\n",
    "|Variable|What it is|What are its values|How is it used|\n",
    "|--|--|--|\n",
    "|$x_1$|Scalar feature|Annual GDP|Used as training inputs|\n",
    "|$w_1$|Scalar weight|Learned by model|Used for computing $\\hat{y}$|\n",
    "|$\\hat{y}$|Scalar prediction|Result of $w^Tx$|Used for training output|\n",
    "|$y$|Scalar truth or target|Annual Foreign Reserves|Used for minimizing training error (cost)|\n",
    "\n",
    "Note that we use subscripts here, $x_1$ and $w_1$ because we only have a scalar input value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivation of Linear Function\n",
    "You may recall that a linear function has a y-intercept term, $b$:\n",
    "\n",
    "$$\\hat{y} = w_1x_1 + b$$\n",
    "\n",
    "This is sometimes also called the \"bias\" (because it \"shifts\" the output by a constant value)\n",
    "\n",
    "If we rewrite the above equation as:\n",
    "\n",
    "$$\\hat{y} = w_0x_0 + w_1x_1$$ \n",
    "\n",
    "where $x_0 = 1$, and $w_0 = b$\n",
    "\n",
    "Then, it becomes the following vector-vector product:\n",
    "\n",
    "$$\\hat{y} = \\left(\\begin{array}{c c}\n",
    "   w_0 & w_1\n",
    "\\end{array} \\right) \\left(\\begin{array}{c}\n",
    "   x_0 \\\\\n",
    "   x_1\n",
    "\\end{array} \\right)$$\n",
    "\n",
    "Which is our \"textbook\" linear function:\n",
    "\n",
    "$$\\hat{y} = w^Tx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Linear Functions\n",
    "\n",
    "Let's plot some examples of linear functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "x1 = np.arange(-5, 5, 1)\n",
    "x0 = np.ones(x1.shape)\n",
    "x = np.vstack([x0, x1])\n",
    "\n",
    "# weights\n",
    "w1 = np.array([1, -4, 8]) # slope\n",
    "w0 = np.array([-6, 0, 6]) # y-intercept\n",
    "w = np.vstack([w0, w1])\n",
    "\n",
    "# linear function\n",
    "y_hat = np.dot(w.T, x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for i in range(0, y_hat.shape[0]):\n",
    "    ax.plot(x1, y_hat[i], label='{}x + {}'.format(w1[i], w0[i]))\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "ax.set(title='Single-variable linear functions', xlabel='x', ylabel='y_hat')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Linear Regression\n",
    "Let's train our Linear Regression model in Python using [scikit-learn](http://scikit-learn.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split\n",
    "\n",
    "To train a model, it is good practice to split your data into two sets:\n",
    "- training set\n",
    "- test set\n",
    "\n",
    "This allows the model to avoid \"overfitting\", which is when the model is \"too specific\" to the data we give it. \n",
    "- The danger of overfitting is that the model can only work well with the data we've used to train it.\n",
    "- To avoid this, we usually \"hold back\" some of the data for \"independent testing\". This becomes the test set.\n",
    "\n",
    "The above is the layman's explanation. We'll cover overfitting in more formal detail in the next module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_back_percent = 20\n",
    "sample_size = len(df_dataset)\n",
    "test_sample_size = int(np.rint(hold_back_percent * sample_size / 100))\n",
    "\n",
    "print('number of data samples', sample_size)\n",
    "print('training test split', hold_back_percent)\n",
    "print('number of samples reserved for testing', test_sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the dataset\n",
    "\n",
    "Before doing the train/test split, we'll also shuffle the data so we can make the training and testing more \"fair\" (or closer to real life usage of the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_shuffled = df_dataset.sample(frac=1).reset_index()\n",
    "\n",
    "df_dataset_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_dataset_shuffled.iloc[0:-test_sample_size]\n",
    "df_test = df_dataset_shuffled.iloc[-test_sample_size:-1]\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model\n",
    "\n",
    "We'll use [sklearn.linear_model.LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) to fit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# LinearRegression is designed generically to work with multiple features,\n",
    "# and expects x to be a 2D array.\n",
    "x1_train = df_train.x1.values.reshape(-1, 1) # add 1 extra dimension\n",
    "\n",
    "%time model.fit(x1_train, df_train.y)\n",
    "\n",
    "print('Coefficient (w1)', model.coef_)\n",
    "print('Intercept (w0)', model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Validation\n",
    "Now that we've trained our model, the next  step is to evaluate how well training went.\n",
    "\n",
    "Steps:\n",
    "1. Get predictions, $\\hat{y}$, using `LinearRegression.predict()`\n",
    "2. Compute the [mean-squared error](http://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error) and [r2 score](http://scikit-learn.org/stable/modules/model_evaluation.html#r2-score-the-coefficient-of-determination) of the predictions against the truth $y$.\n",
    " - A smaller mean-squared error is better\n",
    " - A variance score of 1 means a perfect prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearRegression is designed generically to work with multiple features,\n",
    "# and expects x to be a 2D array.\n",
    "x1_test = df_test.x1.values.reshape(-1, 1)\n",
    "y_test = df_test.y.values\n",
    "\n",
    "y_hat = model.predict(x1_test)\n",
    "\n",
    "print('Truth:', y_test)\n",
    "print('Predictions:', y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huh?\n",
    "Hmm, the mean-squared error is really high.  What's going on?\n",
    "\n",
    "Since the R2 score is actually quite good, we consult the formula of mean-squared error:\n",
    "\n",
    "![mse-formula](http://scikit-learn.org/stable/_images/math/44f36557fef9b30b077b21550490a1b9a0ade154.png)\n",
    "\n",
    "The numerical values are in tens and hundreds of thousands. A relatively \"small\" difference of hundreds can be magnified to thousands, summed across the number of test samples.\n",
    "\n",
    "Let's try [mean_squared_log_error](http://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-log-error) instead. \n",
    "\n",
    "![msle-formula](http://scikit-learn.org/stable/_images/math/7ab9dd9a29d207d773d08e4d1a0fc370f9b1fa35.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "mean_squared_log_error(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better...\n",
    "\n",
    "### Plot predictions vs. truth\n",
    "\n",
    "Finally, let's visualize the predictions against the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "y_hat_train = model.predict(x1_train)\n",
    "\n",
    "ax.plot(y_hat_train, x1_train, label='prediction (test)')\n",
    "ax.plot(y_hat, x1_test, label='prediction (train)')\n",
    "\n",
    "ax.scatter(y_test, x1_test, marker='x', label='truth (test)')\n",
    "ax.scatter(df_train.y.values, x1_train, marker='x', label='truth (train)')\n",
    "\n",
    "ax.set(xlabel='Annual GDP S$ million',\n",
    "       ylabel='Annual Total Foreign Reserves S$ million')\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we get in the end?\n",
    "\n",
    "In the (involved) process of training a machine learning model, it can be easy to forget what we actually get in the end.\n",
    "\n",
    "### Summary\n",
    "1. What: we've trained a linear regression model based on historical annual GDP and foreign reserves data, to try to find a relationship between the two.\n",
    "\n",
    "2. Metrics: MLSE of 0.022, R2-score of 0.999\n",
    "\n",
    "3. This model can be deployed to predict the Total Foreign Reserves, given the Annual GDP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment use case\n",
    "\n",
    "Note that the actual use case is not that realistic, because Foreign Reserves are affected by other factor as well, such as policy decisions.\n",
    "\n",
    "This brings up another interesting point.  Whereas machine learning can find correlation parameters, it won't tell you if the correlation actually makes sense.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine you are the future Finance Minister,\n",
    "# here's how the model might be used in deployment scenarios\n",
    "\n",
    "gdp = np.array([200000, -200000, 0, 50000000])\n",
    "predicted_foreign_reserves = model.predict(gdp.reshape(-1, 1))\n",
    "\n",
    "for i in range(len(gdp)):\n",
    "    print('S$%d million GDP => Foreign Reserves S$%.2f million'\n",
    "         %(gdp[i], predicted_foreign_reserves[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading List\n",
    "\n",
    "|Material|Read it for|URL|\n",
    "|--|--|--|\n",
    "|Deep Learning Basics, Chapter 5, Pages 105-107|Linear Regression Theory|http://www.deeplearningbook.org/contents/ml.html|\n",
    "|Ordinary Least Squares Linear Regression|Programming Example|http://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('VlpFaak0ZKs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "livereveal": {
   "autolaunch": false,
   "overlay": "<div class='logo'><img src='assets/Stackup_Logo_Small.png' width='90%'/></div>"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
