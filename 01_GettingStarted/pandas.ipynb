{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![pandas](https://upload.wikimedia.org/wikipedia/commons/4/45/Pandas_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Topics\n",
    "\n",
    "- Series vs. DataFrames\n",
    "- Querying, indexing, slicing\n",
    "- Combining and splitting data\n",
    "- Handling missing data\n",
    "- Continuous vs. categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Workshop: Pandas and Data Manipulation\n",
    "\n",
    "In this workshop, we will use pandas to load, describe, and query datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Cheatsheet\n",
    "\n",
    "https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### References\n",
    "\n",
    "1. https://pandas.pydata.org/pandas-docs/stable/  \n",
    "2. Python Data Science Handbook by Jake VanderPlas\n",
    "3. Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython by Wes McKinney\n",
    "4. https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Installation\n",
    "\n",
    "Windows: Start Button -> \"Anaconda Prompt\"\n",
    "\n",
    "Ubuntu / MacOS: conda should be in your path\n",
    "\n",
    "Activate the environment\n",
    "\n",
    "```\n",
    "conda activate mldds01\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Pandas should already be installed. If not, install it:\n",
    "\n",
    "```\n",
    "conda install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Tip: You can check the versions installed by calling Python with a script:\n",
    "```\n",
    "python -c \"import pandas; print(pandas.__version__)\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### SGD to USD Exchange Rate Data\n",
    "\n",
    "Similar to the NumPy workshop, we'll use the historical SGD to USD exchange rates from data.gov.sg to demonstrate some Pandas concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame('https://data.gov.sg/dataset/exchange-rates-sgd-per-unit-of-usd-average-for-period-annual/resource/f927c39b-3b44-492e-8b54-174e775e0d98/view/43207b9f-1554-4afb-98fe-80dfdd6bb4f6', width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Download Instructions\n",
    "\n",
    "You should already have this dataset from the NumPy workshop. If not, here are the instructions:\n",
    "\n",
    "1. Go to https://data.gov.sg/dataset/exchange-rates-sgd-per-unit-of-usd-average-for-period-annual\n",
    "2. Click on the `Download` button\n",
    "3. Unzip and extract the `.csv` file. Note the path for use below.\n",
    "\n",
    "Note: on Windows, you may wish to rename the unzipped folder path to something shorter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Import the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Two main data structures\n",
    "\n",
    "1. Series\n",
    "2. DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Series\n",
    "```\n",
    "pandas.Series(data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)\n",
    "```\n",
    "- Similar to 1-d numpy array but with more flexible explicit indexing\n",
    "- Has two components : index and value for each element\n",
    "- A bit similar concept as dictionary\n",
    "- [more here..](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### DataFrame\n",
    "```\n",
    "pandas.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)\n",
    "```\n",
    "- The primary pandas data structure\n",
    "- Tabular format similar to excel\n",
    "- Two-dimensional, potentially heterogeneous tabular data\n",
    "- structure with labeled axes (rows and columns). Row and columns index\n",
    "- Can be thought of as a dict-like container for Series objects. \n",
    "- [more here..](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Read data from CSV to a Series\n",
    "\n",
    "You can use `pandas.read_csv` to read data into:\n",
    "- A Series, if the data contains only 1 column and you specify the `squeeze=True` option, or\n",
    "- A DataFrame, for any number of columns. This is the default behavior because the DataFrame is the most flexible.\n",
    "\n",
    "[more here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into a series\n",
    "#\n",
    "# parse_dates: which column(s) to parse dates\n",
    "# index_col: which zeroth indexed column to use the index\n",
    "# infer_datetime_format may speed up the date parsing\n",
    "sgd_usd_series = pd.read_csv('/tmp/exchange-rates/exchange-rates-sgd-per-unit-of-usd-daily.csv',\n",
    "                             parse_dates=['date'], index_col=0, infer_datetime_format=True,\n",
    "                             squeeze=True)\n",
    "\n",
    "# inspect the first 10 values\n",
    "sgd_usd_series.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_usd_series.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into a data frame\n",
    "sgd_usd_df = pd.read_csv('/tmp/exchange-rates/exchange-rates-sgd-per-unit-of-usd-daily.csv',\n",
    "                         parse_dates=['date'], index_col=0, infer_datetime_format=True)\n",
    "\n",
    "# inspect the first 10 values\n",
    "sgd_usd_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_usd_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data without parsing dates\n",
    "temp = pd.read_csv('/tmp/exchange-rates/exchange-rates-sgd-per-unit-of-usd-daily.csv',\n",
    "                   index_col=0)\n",
    "\n",
    "# inspect the first 10 values\n",
    "temp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype of index is a string\n",
    "temp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# with parse_dates = ['date'], dtype of index is a datetime64\n",
    "sgd_usd_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv has many other functions for reading in CSV data\n",
    "# such as custom parsing functions, or custom delimiters\n",
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get values or indices\n",
    "\n",
    "Series\n",
    "- use series.values\n",
    "- use series.index\n",
    "\n",
    "DataFrame\n",
    "- use df.values\n",
    "- use df.index\n",
    "\n",
    "Note: these are properties, not function calls with ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset:\n",
    "- Series.values is a 1 dimensional numpy.array\n",
    "- DataFrame.values is not. It's actually 2 dimensional:\n",
    "\n",
    "    number of samples (rows) x 1 (column)\n",
    "   \n",
    "This is because DataFrame is a more general data structure that can hold more columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_usd_series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sgd_usd_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_usd_series.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_usd_series.values.ndim # rank = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_usd_df.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_usd_df.values.ndim # rank = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip: you can flatten the 3993 x 1 numpy array\n",
    "sgd_usd_df.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The .index is the same whether it is a Series or a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_usd_series.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_usd_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Get the summary\n",
    "\n",
    "Try these on `sgd_usd_series` and `sgd_usd_df`. \n",
    "\n",
    "|  |  |\n",
    "|--|--|\n",
    "|df.columns | Describe DataFrame columns|\n",
    "|df.info() | Information on a DataFrame |\n",
    "|s.count(), df.count() | Number of non-NA values|\n",
    "|s.count() | Number of non-NA values|\n",
    "\n",
    "Note: these are from the Cheatsheet. Series supports fewer methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Get statistics\n",
    "\n",
    "Try these on `sgd_usd_series` and `sgd_usd_df`. \n",
    "\n",
    "|  |  |\n",
    "|--|--|\n",
    "|s.sum(), df.sum() | Sum of values|\n",
    "|s.cumsum(), df.cumsum() | Cummulative sum of values |\n",
    "|s.min()/s.max(), df.min()/df.max() | Minimum/maximum values|\n",
    "|s.idxmin()/series.idxmax(), df.idxmin()/df.idxmax() | Minimum/Maximum index value|\n",
    "|s.describe(), df.describe() | Summary statistics |\n",
    "|s.mean(), df.mean() | Mean of values |\n",
    "|s.median(), df.median() | Median of values | \n",
    "\n",
    "Note: these are from the Cheatsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Joins\n",
    "\n",
    "Let's say we need to also show Singapore Dollar and Renminbi (CNY) exchange rates, but from a different data set.\n",
    "\n",
    "This dataset is already downloaded for you in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# data source: https://www.exchangerates.org.uk\n",
    "sgd_cny_df = pd.read_csv('data/sgd_cny_rates_daily.csv',\n",
    "                          parse_dates=True, index_col=0, infer_datetime_format=True)\n",
    "print('First 5 entries:')\n",
    "sgd_cny_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sgd_cny_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sgd_usd_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "`sgd_cny_df`: DatetimeIndex: 3224 entries, 2018-05-27 to 2009-10-06\n",
    "\n",
    "`sgd_usd_df`: DatetimeIndex: 3993 entries, 1988-01-08 to 2015-10-19\n",
    "\n",
    "- have different date ranges\n",
    "- one is in decreasing time order, the other is increasing time order \n",
    "\n",
    "Pandas DataFrames make it easy to join these datasets together based on index.\n",
    "\n",
    "You can do this without looping over the data, using `DataFrame.join()`\n",
    "\n",
    "[more info..](https://pandas.pydata.org/pandas-docs/stable/merging.html#joining-on-index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_usd_df.join?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Default join is an `left` join, where the index of the left series (`sgd_usd_df`) is preserved.\n",
    "\n",
    "sgd_usd_cny = sgd_usd_df.join(sgd_cny_df)\n",
    "sgd_usd_cny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can remove the NaN entries using dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sgd_usd_cny = sgd_usd_cny.dropna()\n",
    "sgd_usd_cny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The result is a DataFrame with entries where both exchange rates are present.\n",
    "\n",
    "Entries where either SGD-USD or SGD-CNY are missing are excluded.\n",
    "\n",
    "Note that even though the index for the series are in different order, join will still work because it matches the individual index values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### When in doubt, visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's visualize what we just did by plotting the dataframes.\n",
    "\n",
    "You should have already installed matplotlib. If not, do this:\n",
    "```\n",
    "conda install matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the names of the columns\n",
    "sgd_usd_cny.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(20,15),\n",
    "                              sharex=True) # common x-axis for all subplots\n",
    "\n",
    "ax1.set_title('Original series')\n",
    "ax1.plot(sgd_usd_df, label='SGD/USD')\n",
    "ax1.plot(sgd_cny_df, label='SGD/CNY')\n",
    "ax1.legend(loc='upper center', shadow=True, fontsize='x-large')\n",
    "\n",
    "ax2.set_title('After join() and dropna()')\n",
    "ax2.plot(sgd_usd_cny['exchange_rate_usd'], label='SGD/USD')\n",
    "ax2.plot(sgd_usd_cny['Singapore Dollar to Chinese Yuan'], label='SGD/CNY')\n",
    "ax2.legend(loc='upper center', shadow=True, fontsize='x-large')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_cny_usd = sgd_cny_df.join(sgd_usd_df).dropna()\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(20,15),\n",
    "                              sharex=True) # common x-axis for all subplots\n",
    "\n",
    "ax1.set_title('Original series')\n",
    "ax1.plot(sgd_usd_df, label='SGD/USD')\n",
    "ax1.plot(sgd_cny_df, label='SGD/CNY')\n",
    "ax1.legend(loc='upper center', shadow=True, fontsize='x-large')\n",
    "\n",
    "ax2.set_title('After join() and dropna()')\n",
    "ax2.plot(sgd_cny_usd['exchange_rate_usd'], label='SGD/USD')\n",
    "ax2.plot(sgd_cny_usd['Singapore Dollar to Chinese Yuan'], label='SGD/CNY')\n",
    "ax2.legend(loc='upper center', shadow=True, fontsize='x-large')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Pandas, like SQL\n",
    "\n",
    "If you have worked with SQL or databases before, the DataFrame.join() is conceptually the same as SQL.\n",
    "\n",
    "[Here's](https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html) a guide that compares Pandas with SQL.\n",
    "\n",
    "This SQL:\n",
    "```\n",
    "SELECT *\n",
    "FROM tips\n",
    "WHERE time = 'Dinner' AND tip > 5.00;\n",
    "\n",
    "```\n",
    "Becomes this in pandas:\n",
    "\n",
    "```\n",
    "tips[(tips['time'] == 'Dinner') & (tips['tip'] > 5.00)]\n",
    "```\n",
    "\n",
    "We'll do an example with queries to demonstrate how you can think of Pandas as conceptually equivalent to SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Exercise: Querying a DataFrame\n",
    "\n",
    "Let's say you want to query a DataFrame using something equivalent to this SQL syntax:\n",
    "\n",
    "```\n",
    "SELECT *\n",
    "FROM sgd_usd_cny\n",
    "WHERE date >= '2012-01-01' AND date < '2013-01-01';\n",
    "```\n",
    "\n",
    "What will you use in Pandas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Use pandas to find all exchange rates from 2012, for the sgd_usd_cny DataFrame\n",
    "#\n",
    "# Refer to https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html\n",
    "#\n",
    "# Hint 1: use pd.to_datetime\n",
    "# start = pd.to_datetime('2012-01-01')\n",
    "# end = pd.to_datetime('2013-01-01')\n",
    "#\n",
    "# Hint 2: use sgd_usd_cny.index to compare against the date time\n",
    "#\n",
    "# Hint 3: add parenthesis for the boolean conditions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Indexing and Slicing: iloc, loc\n",
    "\n",
    "|  |  |\n",
    "|--|--|\n",
    "|iloc|Select by position|\n",
    "|loc|Select by label|\n",
    "|iat|Get scalar value by position (fast iloc)\n",
    "|at|Get scalar value by label (fast loc)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![loc iloc](assets/pandas/Pandas-selections-and-indexing.png)\n",
    "(image: shanelynn.ie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### loc, at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sgd_usd_cny.loc[:4] # error (because index is time, not integer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# use a DateTimeIndex for row selector\n",
    "sgd_usd_cny.loc[pd.to_datetime('2009-10-08'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a column selector\n",
    "sgd_usd_cny.loc[pd.to_datetime('2009-10-08'), 'exchange_rate_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast single-value access using .at\n",
    "sgd_usd_cny.at[pd.to_datetime('2009-10-08'), 'exchange_rate_usd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### iloc, iat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sgd_usd_cny.iloc[1, :] # select by row position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sgd_usd_cny.iloc[1]['exchange_rate_usd'] # select by row position, column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_usd_cny.iat[1, 0] # select by row position, column position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sgd_usd_cny.iloc[:4, :] # select by row slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Combining with boolean conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logical / boolean row index\n",
    "sgd_usd_cny.loc[sgd_usd_cny.exchange_rate_usd < 1.21, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# more selectors\n",
    "sgd_usd_cny.loc[sgd_usd_cny.exchange_rate_usd > 1.425]['Singapore Dollar to Chinese Yuan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc does not support boolean indexing, because it is NOT label-based\n",
    "\n",
    "sgd_usd_cny.iloc[sgd_usd_cny.exchange_rate_usd < 1.21, :] # error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Adding and removing rows / columns\n",
    "\n",
    "|  |  |\n",
    "|--|--|\n",
    "|s.drop(), df.drop()| Drop row (axis=0)|\n",
    "|s.drop('col', axis=1), df.drop('col', axis=1)| Drop column (axis=1)|\n",
    "|pd.concat([s1, s2], axis=0), pd.concat([df1, df2], axis=0)|Concatenate rows (axis=0)|\n",
    "|pd.concat([s1, s2], axis=1), pd.concat([df1, df2], axis=1)|Concatenate columns (axis=1)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append a few rows of empty data\n",
    "index = pd.date_range(start='2015-10-20', end='2015-10-22')\n",
    "\n",
    "new_df = pd.DataFrame(index=index,\n",
    "                      columns=sgd_usd_cny.columns)\n",
    "result = pd.concat([sgd_usd_cny, new_df], axis=0) # axis=0 for rows\n",
    "result.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the rows\n",
    "index = pd.date_range(start='2015-10-20', end='2015-10-22')\n",
    "\n",
    "result.drop(index, inplace=True)\n",
    "result.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Exercises: add and remove columns\n",
    "\n",
    "1. Add a new column called 'SGD to Euro' with empty values\n",
    "2. Drop the column you just added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Add a new column called 'SGD to Euro', with empty values\n",
    "#\n",
    "# Hint 1: use index=sgd_usd_cny.index\n",
    "# Hint 2: what value should axis be in pd.concat?\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the column you just added\n",
    "# \n",
    "# Hint: use inplace=True so that the change is performed in place\n",
    "# Hint: what value should axis be?\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Missing data\n",
    "\n",
    "We saw how to add columns and rows without any data.  Now we'll explore how to deal with the missing data.\n",
    "\n",
    "Here are some ways:\n",
    "\n",
    "|  |  |\n",
    "|--|--|\n",
    "|dropna|Drop missing values|\n",
    "|fillna(new_value)|Fill missing values with new_value|\n",
    "|interpolate()|Use linear interpolation|\n",
    "\n",
    "We've already seen how dropna() works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.dropna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.fillna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.interpolate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "index=pd.date_range(start='2015-10-20', end='2015-10-22')\n",
    "\n",
    "new_df = pd.DataFrame(index=index,\n",
    "                      columns=sgd_usd_cny.columns)\n",
    "result = pd.concat([sgd_usd_cny, new_df], axis=0)\n",
    "result.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping the NaN values\n",
    "result.dropna().tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Filling the NaN values with a meaningful value, such as the median\n",
    "median = result.median()\n",
    "result.fillna(median).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Using linear interpolation\n",
    "result.interpolate().tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Categorical Data\n",
    "\n",
    "The previous dataset shows how to use pandas for datasets with continous variables (the exchange rate).\n",
    "\n",
    "Let's see another dataset that demonstrates how to use pandas for categorical variables (such as classes of things).\n",
    "\n",
    "We'll use the `Annual Motor Vehicle Population by Vehicle Type` dataset from data.gov.sg.\n",
    "\n",
    "Reference: https://pandas.pydata.org/pandas-docs/stable/visualization.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Instructions\n",
    "\n",
    "1. Go to https://data.gov.sg/dataset/annual-motor-vehicle-population-by-vehicle-type\n",
    "2. Click on the Download button\n",
    "3. Unzip and extract the .csv file. Note the path for use below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/tmp/motor-vehicles/annual-motor-vehicle-population-by-vehicle-type.csv',\n",
    "                 parse_dates=['year'], index_col=0, infer_datetime_format=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Grouping and aggregating categories\n",
    "Since this series has multiple entries for the same date, we can group rows together using `group_by`.\n",
    "\n",
    "For example, to find the total number of vehicles per year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby(df.index)['number'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can also plot the total number of vehicles per year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ax = df.groupby(df.index)['number'].sum().plot(marker='o')\n",
    "ax.set(ylabel='Vehicle Population',\n",
    "       xlabel='Year',\n",
    "       title='Annual Vehicle Population')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Processing per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# get the unique classes\n",
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get just the dataFrame for a category\n",
    "buses = df[df.category =='Buses']\n",
    "buses.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of each category\n",
    "for name in df.category.unique():\n",
    "    print(name, df.loc[df.category == name, \"category\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a year (2009) and plot the distributions across types\n",
    "df_2009 = df[df.index == pd.to_datetime('2009')]\n",
    "df_2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series with the type as the index, and the numbers as values\n",
    "s_2009_type = df_2009.number\n",
    "s_2009_type.index = df_2009.type\n",
    "s_2009_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the bar chart\n",
    "s_2009_type.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's ignore private cars because they outweigh everything else\n",
    "s_2009_type[s_2009_type.index != \"Private cars\"].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Pivot Table\n",
    "\n",
    "Pandas supports creating a pivot table, similar to what is available from Excel. \n",
    "\n",
    "This is useful when we would like to group categories by year, and then display them in stacked bar plots, with year on the x-axis.\n",
    "\n",
    "[pandas.pivot_table()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html)\n",
    "\n",
    "[bar plots](https://pandas.pydata.org/pandas-docs/stable/visualization.html#bar-plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Why pivot table?\n",
    "\n",
    "The original dataset has each category as a separate entry in the `category` column.\n",
    "\n",
    "|year|category|type|number|\n",
    "|--|--|--|--|\n",
    "|2005-01-01|Cars & Station-wagons|Private cars|401638|\n",
    "|2005-01-01|Cars & Station-wagons|Company cars|14926|\n",
    "\n",
    "For the bar plot, we need each category as a separate column. The entry under each category will be the number of vehicles for that year.\n",
    "\n",
    "Something like:\n",
    "\n",
    "|year|Buses|Cars & Station-wagons|Goods & Other Vehicles|...|\n",
    "|--|--|--|--|\n",
    "|2005-01-01|2640|438194|128193|...|\n",
    "|2006-01-01|...|...|...|...|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Original dataset, filtered by year 2005 as an illustration\n",
    "df[df.index == pd.to_datetime('2005')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Create pivot table that is:\n",
    "- indexed by year\n",
    "- using category as the columns\n",
    "- numbers as values\n",
    "\n",
    "Each category has multiple entries (one for each type), so we also need to specify this:\n",
    "- aggregate function to sum up the numbers for that category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pv_year_category = pd.pivot_table(df, index=\"year\", columns=\"category\",\n",
    "                                  values=\"number\", aggfunc=np.sum)\n",
    "\n",
    "pv_year_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Hmm, there are some NaN values.\n",
    "\n",
    "On closer examination, the culprit is 2017, where \"and\" replaced \"&\" in the category name.\n",
    "\n",
    "We will need to fix those entries so that the name matches.\n",
    "\n",
    "### Question\n",
    "Can you explain why can't we just use `dropna(axis=1)` to drop columns with NaN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Show the problematic dataframes (2017)\n",
    "df_2017 = df.loc[pd.to_datetime('2017'), :]\n",
    "df_2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Fix the category names for year = 2017 by replacing \"and\" with \"&\".\n",
    "\n",
    "Avoid looping on individual rows.\n",
    "\n",
    "For a given category, you can:\n",
    "1. Use the syntax `df.loc[row_indexer, col_indexer]` to get a **view** for each incorrect category\n",
    "2. Assign the correct value to that view\n",
    "\n",
    "#### Note on why we use `DataFrame.loc`:\n",
    "\n",
    "Using `df.loc` with assignment will avoid this SettingWithCopyWarning, because loc returns a view, not a copy of the DataFrame:\n",
    "```\n",
    "Traceback (most recent call last)\n",
    "     ...\n",
    "SettingWithCopyWarning:\n",
    "     A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "     Try using .loc[row_index,col_indexer] = value instead\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Your code needs to fix these categories:\n",
    "#\n",
    "#     Incorrect                   Correct\n",
    "#     ---------------------------------------------------\n",
    "#     Cars and Station-wagons     Cars & Station-wagons\n",
    "#     Goods and Other Vehicles    Goods & Other Vehicles\n",
    "#     Motorcycles & Scooters      Motorcycles\n",
    "#     ----------------------------------------------------\n",
    "#\n",
    "\n",
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Let's generate the pivot_table again, the NaNs should now go away\n",
    "pv_year_category = pd.pivot_table(df, index=\"year\", columns=\"category\",\n",
    "                                  values=\"number\", aggfunc=np.sum)\n",
    "\n",
    "pv_year_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's plot the bar chart.\n",
    "\n",
    "We are doing a bit more matplotlib stuff here to make the bar chart readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "pv_year_category.plot(kind='bar', stacked=True, ax=ax)\n",
    "ax.set(title='Annual Motor Vehicle Population by Category',\n",
    "       ylabel='Vehicle Population',\n",
    "       xlabel='Year')\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "# Due to: https://github.com/pandas-dev/pandas/issues/1918\n",
    "# Can't just do: ax.xaxis.set_major_formatter(mdates.FormatStrFormatter('%Y'))\n",
    "ax.xaxis.set_major_formatter(plt.FixedFormatter(pv_year_category.index.to_series().dt.strftime(\"%Y\")))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "livereveal": {
   "autolaunch": false,
   "overlay": "<div class='logo'><img src='assets/Stackup_Logo_Small.png' width='90%'/></div>"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
