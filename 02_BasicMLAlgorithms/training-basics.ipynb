{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![training](assets/training-basics/puppy-training.jpg)\n",
    "\n",
    "(image: amazon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Concepts in training models\n",
    "- Loss functions\n",
    "- Gradient descent\n",
    "- Overfitting, underfitting, bias, variance\n",
    "- Regularization\n",
    "- Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Objective: a model that trains fast and performs well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Loss Functions\n",
    "\n",
    "What they are: a metric of how far away the predictions are from the truth\n",
    "\n",
    "For example:\n",
    "\n",
    "![MSE](http://scikit-learn.org/stable/_images/math/44f36557fef9b30b077b21550490a1b9a0ade154.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "a.k.a.:\n",
    "- Objective function\n",
    "- Cost function\n",
    "- Error function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Definitions\n",
    "\n",
    "$$x^* = \\arg \\min f(x)$$\n",
    "\n",
    "where $x^*$ = value that minimizes the loss function $f(x)$\n",
    "\n",
    "The process of finding $x^*$ is called \"Optimization\". It usually involves running some type of Gradient Descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loss Function Examples\n",
    "\n",
    "Scikit-learn:\n",
    "- [Mean squared error](http://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error): `sklearn.metrics.mean_squared_error(y_true, y_pred)`\n",
    "- [Log loss](http://scikit-learn.org/stable/modules/model_evaluation.html#log-loss): `sklearn.metrics.log_loss(y_true, y_pred)`\n",
    "- [Zero one loss](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.zero_one_loss.html#sklearn.metrics.zero_one_loss)\n",
    "`sklearn.metrics.zero_one_loss(y_true, y_pred)`\n",
    "- etc\n",
    "\n",
    "Keras:\n",
    "- https://keras.io/losses/\n",
    "- `keras.losses.mean_squared_error(y_true, y_pred)`\n",
    "- `keras.losses.binary_crossentropy(y_true, y_pred)`\n",
    "- etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Gradient Descent\n",
    "\n",
    "What it is: technique for minimizing loss function for a given model\n",
    "\n",
    "Objective: find $w^*$ such that $$w^* = \\underset{w}\\arg \\min{f\\big(y_{true}, y_{pred}\\big)}$$\n",
    "\n",
    "$$w^* = \\underset{w}\\arg \\min{f\\big(y_{true}, g(x, w)\\big)}$$\n",
    "\n",
    "\n",
    "where\n",
    "- $f(...)$ is the loss function\n",
    "- $w$ are the weights\n",
    "- $g(x, w)$ is the model that computes $y_{pred}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient descent algorithm\n",
    "\n",
    "1. Initialize $w$ to some value (e.g. random)\n",
    "2. Compute gradient of $f\\big(y_{true}, g(x, w)\\big)$\n",
    "3. Update $w$ by a \"tiny factor\" in the negative of the gradient\n",
    "4. Repeat 2-3 until loss is \"good enough\"\n",
    "\n",
    "The \"tiny factor\" is known as the \"learning rate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Workshop: Gradient descent, the animated series\n",
    "\n",
    "![descent!](assets/training-basics/descend.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Credits: https://jed-ai.github.io/py1_gd_animation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "livereveal": {
   "autolaunch": false,
   "overlay": "<div class='logo'><img src='assets/Stackup_Logo_Small.png' width='90%'/></div>"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
