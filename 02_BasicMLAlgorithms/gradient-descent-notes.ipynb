{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Gradient Descent - Notes\n",
    "\n",
    "![gradient_descent](assets/training-basics/gradient_descent.png)\n",
    "\n",
    "(image: https://hackernoon.com/gradient-descent-aynk-7cbe95a778da)\n",
    "\n",
    "Supplementary material that covers:\n",
    "- why we need gradient descent\n",
    "- how it is tuned\n",
    "- various options for it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why do we need Gradient Descent?\n",
    "\n",
    "- Computing what weights $w$ give the lowest cost is expensive\n",
    "  - Lots of possible values of $w$\n",
    "  - $w$ can have multiple dimensions (when you have multiple $x$ features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why do we need Gradient Descent?\n",
    "\n",
    "- Gradient Descent is an Approximation Algorithm\n",
    "  - Finds the set of $w$ that can give \"low enough\" cost\n",
    "  - Uses the direction of change in the cost function (the gradient)\n",
    "  - The direction of change is relative to the values of $w$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we tune Gradient Descent?\n",
    "\n",
    "- Pick a learning rate that is not to fast or too slow\n",
    "- Pick how the learning rate can be updated during training.\n",
    "- Pick how long we train (number of epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Algorithms\n",
    "\n",
    "- Why do we have so many algorithms?\n",
    "  - Because the approximation may not always find the minimum cost\n",
    "  - Because we want to train faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variations around Speed & Noise\n",
    "\n",
    "- How fast we train\n",
    "  - Gradient Descent: all samples (...slow...)\n",
    "  - Stochastic Gradient Descent: random 1 sample (fast, but noisy)\n",
    "  - Minibatch SGD: small batches (fast, less noisy)\n",
    "  - Minibatch SGD + momentum: (fast, even less noisy)\n",
    "\n",
    "\n",
    "When used:\n",
    "- SGD is very common in machine learning\n",
    "- Minibatch variations are common in deep learning (keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variations around Learning Rate\n",
    "\n",
    "- How to pick the \"best\" learning rate\n",
    "  - Make learning rate smaller as we train longer\n",
    "    - Decaying learning rate\n",
    "    - When used: common practice\n",
    "  - Make learning rate slow down for steeper gradients, speed up for shallower gradients\n",
    "    - RMSProp, AdaGrad, Adam, ...\n",
    "    - When used: deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Algorithms (pseudocode)\n",
    "\n",
    "## Gradient Descent (aka Batch Gradient Descent)\n",
    "```\n",
    "params = random_initialize()\n",
    "\n",
    "for i in range(n_epochs):\n",
    "\n",
    "  # Entire data is trained each time\n",
    "  params_grad = evaluate_gradient(loss_function, data, params)\n",
    "  params = params - learning_rate * params_grad\n",
    "  \n",
    "return params\n",
    "```\n",
    "\n",
    "## Stochastic Gradient Descent\n",
    "\n",
    "Difference with GD: picks a random sample to train\n",
    "\n",
    "```\n",
    "params = random_initialize()\n",
    "\n",
    "for i in range(n_epochs):\n",
    "  np.random.shuffle(data)\n",
    "\n",
    "  # Gets one random example to train at a time\n",
    "  for example in data:\n",
    "    params_grad = evaluate_gradient(loss_function, example, params)\n",
    "    params = params - learning_rate * params_grad\n",
    "\n",
    "return params\n",
    "```\n",
    "\n",
    "sklearn: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html\n",
    "\n",
    "(Inspiration: http://ruder.io/optimizing-gradient-descent/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "## Minibatch SGD\n",
    "\n",
    "Difference with SGD: picks a batch (see `get_batches`) to train\n",
    "\n",
    "```\n",
    "params = random_initialize()\n",
    "\n",
    "for i in range(n_epochs):\n",
    "  np.random.shuffle(data)\n",
    "\n",
    "  # Gets a batch of 50 to train at a time\n",
    "  for batch in get_batches(data, batch_size=50):\n",
    "\n",
    "    params_grad = evaluate_gradient(loss_function, batch, params)\n",
    "    params = params - learning_rate * params_grad\n",
    "    \n",
    "return params\n",
    "```\n",
    "\n",
    "## Minibatch SGD + Momentum\n",
    "\n",
    "Difference with Minibatch SGD: uses decaying moving average of previous gradients to update\n",
    "\n",
    "```\n",
    "params = random_initialize()\n",
    "\n",
    "for i in range(n_epochs):\n",
    "  np.random.shuffle(data)\n",
    "  for batch in get_batches(data, batch_size=50):\n",
    "    params_grad = evaluate_gradient(loss_function, batch, params)\n",
    "\n",
    "    # Computes the decaying moving average of past gradients\n",
    "    #   This becomes higher if previous gradient is same direction\n",
    "    #   Lower if previous gradient is opposite direction\n",
    "    velocity = momentum * velocity - learning_rate * params_grad\n",
    "\n",
    "    # Uses the moving average to update\n",
    "    params = params + velocity\n",
    "    \n",
    "return params\n",
    "```\n",
    "\n",
    "Keras implementation:https://github.com/keras-team/keras/blob/master/keras/optimizers.py#L146"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov Accelerated Gradient Descent (NAG)\n",
    "\n",
    "- A variant of Minibatch SGD + Momentum\n",
    "- Look ahead by calculating gradient w.r.t. approximate future value of $\\theta$ (i.e. $\\nabla_{\\theta}L(\\theta - \\gamma v)$)\n",
    "\n",
    "$$v \\leftarrow \\gamma v + \\epsilon \\nabla_{\\theta}L(\\theta - \\gamma v) $$\n",
    "\n",
    "$$\\theta \\leftarrow \\theta - v$$\n",
    "\n",
    "- Allows gradient updates to slow down if the future slope is going upwards\n",
    "- Popular with deep learning (e.g. Baidu DeepSpeech)\n",
    "\n",
    "Keras implementation: https://github.com/keras-team/keras/blob/master/keras/optimizers.py#L146"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Nesterov Accelerated Gradient\n",
    "\n",
    "Difference with Minibatch SGD with Momentum: uses the next possible params to compute gradient.\n",
    "\n",
    "```\n",
    "params = random_initialize()\n",
    "\n",
    "for i in range(n_epochs):\n",
    "  np.random.shuffle(data)\n",
    "  for batch in get_batches(data, batch_size=50):\n",
    "  \n",
    "    # Computes the future params\n",
    "    lookahead_params = params - momentum * velocity\n",
    "\n",
    "    # Get the gradient of the future params\n",
    "    params_grad = evaluate_gradient(loss_function, batch, lookahead_params)\n",
    "\n",
    "    velocity = momentum * velocity + learning_rate * params_grad\n",
    "    params = params - velocity\n",
    "    \n",
    "return params\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Adaptive Learning Rate Strategies\n",
    "\n",
    "- Learning rate will control the amount of gradient update\n",
    "  - Large learning rate: risk overshoot and not converge\n",
    "  - Small learning rate: too slow\n",
    "  - Ideal: start large(r), then reduce as we get closer to minima\n",
    "- Strategies\n",
    "  - Constant learning rate\n",
    "  - Time-based or step-based decay\n",
    "  - Adaptive learning rate\n",
    "    - RMSProp\n",
    "    - AdaGrad\n",
    "    - Adam\n",
    "- What works best depends on your domain (true for **any** optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RMSProp\n",
    "\n",
    "- Divide learning rate by exponentially decaying average of past squared gradients\n",
    "   - Steeper gradients: smaller learning rate\n",
    "- Usually good for RNNs\n",
    "\n",
    "$$E[g^2]_t = 0.9E[g^2]_{t-1} + 0.1g_t^2 $$\n",
    "\n",
    "$$\\theta \\leftarrow \\theta - \\frac{\\epsilon}{\\sqrt{E[g^2]_t + c}} g$$\n",
    "\n",
    "$c$ = small constant to avoid division by zero\n",
    "\n",
    "Keras implementation:\n",
    "https://github.com/keras-team/keras/blob/master/keras/optimizers.py#L209"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### AdaGrad\n",
    "\n",
    "- Adaptive, per-parameter learning rate\n",
    "- Designed for sparse features\n",
    "  - more frequent features: smaller learning rate (e.g. common words in a document)\n",
    "  - more rare features: higher learning rate (e.g. rare words in a document)\n",
    "- learning rate gets updated as parameter gets updated\n",
    "\n",
    "$$\\theta \\leftarrow \\theta - \\frac{\\epsilon}{\\sqrt{G_t + c}} g$$\n",
    "\n",
    "$G_t \\in I\\!R^{d\\times d} $ = diagonal matrix\n",
    "- sum of squares of past gradients\n",
    "- 1 diagonal element per parameter\n",
    "\n",
    "$c$ = small constant to avoid division by zero\n",
    "\n",
    "Keras implementation:\n",
    "https://github.com/keras-team/keras/blob/master/keras/optimizers.py#L276"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Adam (Adaptive Moment Estimation)\n",
    "- Requires less fine-tuning (easier to use)\n",
    "- Estimated first moment (mean): $m \\leftarrow \\beta_1 m + (1-\\beta_1)g$\n",
    "  - Averages out the gradient used for update\n",
    "- Estimated second moment (uncentered variance): $v \\leftarrow \\beta_2 v + (1-\\beta_2)g^2$\n",
    "  - Smooths out the learning rate if gradient is high\n",
    "\n",
    "$$\\theta \\leftarrow \\theta - \\frac{\\epsilon}{\\sqrt{\\hat{v}} + c}\\hat{m}$$\n",
    "- $\\hat{v} = \\frac{v}{1-\\beta_2}$, $\\hat{m} = \\frac{m}{1-\\beta_1}$ to avoid zero bias\n",
    "- $\\beta_1$ and $\\beta_2$ usually 0.9 and 0.999\n",
    "- $c$ = small constant to avoid division by zero\n",
    "\n",
    "Keras implementation:\n",
    "https://github.com/keras-team/keras/blob/master/keras/optimizers.py#L422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Squared Error - Gradients\n",
    "\n",
    "The following example shows how the Partial Derivative of the Mean Square Error function is computed.\n",
    "\n",
    "The model has 2 weights: $\\theta_0$ and $\\theta_1$ (alias for $w_0$ and $w_1$)\n",
    "\n",
    "\n",
    "![gradient MSE](assets/training-basics/ThetaZeroDerivation.png)\n",
    "\n",
    "(image: http://mccormickml.com/2014/03/04/gradient-descent-derivation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![thetazeroderivativeoferror1.png](assets/training-basics/thetazeroderivativeoferror1.png)\n",
    "\n",
    "![ThetaOneDerivativeOfError.png](assets/training-basics/ThetaOneDerivativeOfError.png)\n",
    "\n",
    "(image: http://mccormickml.com/2014/03/04/gradient-descent-derivation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gradientdescentofmsetable](assets/training-basics/gradientdescentofmsetable.png)\n",
    "\n",
    "(image: http://mccormickml.com/2014/03/04/gradient-descent-derivation/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "livereveal": {
   "autolaunch": false,
   "overlay": "<div class='logo'><img src='assets/Stackup_Logo_Small.png' width='90%'/></div>"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
