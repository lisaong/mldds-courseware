{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "![galaxies](assets/classification/hubble_tuning_fork.jpg)\n",
    "\n",
    "(image: [NASA](https://imagine.gsfc.nasa.gov/educators/programs/cosmictimes/educators/guide/1929/nebulae.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Topics\n",
    "\n",
    "- Classification: binary, multi-class\n",
    "- Logistic Regression\n",
    "- Na√Øve Bayes Classification\n",
    "- K-nearest Neighbours\n",
    "- Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Where are we?\n",
    "\n",
    "![one of many cheatsheets but I keep using it](assets/linear-regression/machine-learning-cheet-sheet.png)\n",
    "\n",
    "(image: [sas.com](https://www.sas.com/en_us/insights/analytics/machine-learning.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "\n",
    "Given a sample with $n$ independent features\n",
    "\n",
    "$X^i = [x^i_1, x^i_2, ..., x^i_n]$\n",
    "\n",
    "Predict the probability $P(y)$ that this sample belongs to a class $y$\n",
    "\n",
    "i.e. we \"classify\" the sample as belonging to $y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algorithms for Classification\n",
    "\n",
    "- Logistic Regression*\n",
    "- Naive Bayes*\n",
    "- K-nearest Neighbours*\n",
    "- Support Vector Machines*\n",
    "- Decision Trees and Forests\n",
    "- Neural Networks\n",
    "- etc\n",
    "\n",
    "[* Covered today]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Linear Regression + either Activation or Softmax\n",
    "\n",
    "Activation: Binary Classification\n",
    "\n",
    "Softmax: Multi-class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Binary\n",
    "\n",
    "![your mood today?](assets/classification/logistic-regression.png)\n",
    "\n",
    "(image: dataaspirant.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logistic Sigmoid\n",
    "\n",
    "Converts the output to a value between 0 and 1\n",
    "- 1 can mean True, Happy, ...\n",
    "- 0 can mean False, Sad, ...\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+exp(-x)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Credits: https://ilparle.com/2017/04/21/plot-a-simple-sigmoid-function/\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(-8, 8, 0.1)\n",
    "sigmoid = 1 / (1 + np.exp(-x))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, sigmoid)\n",
    "ax.set(xlabel = 'x', ylabel = 'sigmoid')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multi-Class\n",
    "\n",
    "![mnist logistic regression](assets/classification/mnist-logistic-regression.png)\n",
    "\n",
    "(image: [CNTK](https://cntk.ai/pythondocs/CNTK_103B_MNIST_LogisticRegression.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Softmax\n",
    "\n",
    "Softmax:\n",
    "- Converts multiple outputs to a percentage distribution between 0 and 1\n",
    "- Percentage distribution: numbers all add up to 1 (100%)\n",
    "- Outputs: 0.7 happy, 0.2 depressed, 0.1 unknown\n",
    "\n",
    "Example: [1, 2, 3, 4, 1, 2, 3]\n",
    "\n",
    "Result: [0.024, 0.064, 0.175, 0.475, 0.024, 0.064, 0.175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Credits: https://en.wikipedia.org/wiki/Softmax_function\n",
    "import numpy as np\n",
    "\n",
    "z = [1.0, 2.0, 3.0, 4.0, 1.0, 2.0, 3.0]\n",
    "softmax = lambda x : np.exp(x)/np.sum(np.exp(x))\n",
    "softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![binary v. multiclass](assets/classification/binary_v_multiclass.png)\n",
    "\n",
    "(image: [CNTK](https://cntk.ai/pythondocs/CNTK_103B_MNIST_LogisticRegression.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Libraries\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Iris flower dataset\n",
    "# https://archive.ics.uci.edu/ml/datasets/iris\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Add noisy features to make the problem harder\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=99)\n",
    "\n",
    "print('First 5 training data:', X_train[:5])\n",
    "print('First 5 training labels:', y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print('Number of mislabeled points out of test set of %d points:' % (X_test.shape[0]))\n",
    "print('Logistic Regression: %d, Score: %f' % ((y_test != y_pred_lr).sum(), lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Naive Bayes Classification\n",
    "\n",
    "![naive bayes](assets/classification/naive-bayes.png)\n",
    "\n",
    "(image: [shatterline.com](http://shatterline.com/blog/2013/09/12/not-so-naive-classification-with-the-naive-bayes-classifier/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes Theorem\n",
    "\n",
    "- Inputs: independent features\n",
    "- Outputs: class probabilities\n",
    "  - Bayes Theorem computes the conditional probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Libraries\n",
    "\n",
    "http://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes\n",
    "\n",
    "- Gaussian\n",
    "- Multinomial\n",
    "- Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "# Now that we added noise to our data, we need to scale the features to between [0, 1]\n",
    "# This is because Naive Bayes cannot handle negative features (throws an error)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler.fit(X_train)\n",
    "X_train_minmax = min_max_scaler.transform(X_train)\n",
    "X_test_minmax = min_max_scaler.transform(X_test)\n",
    "\n",
    "nb_titles = ['Gaussian Naive Bayes', 'Multinomial NB', 'Bernouilli NB']\n",
    "nb_models = (naive_bayes.GaussianNB(),\n",
    "             naive_bayes.MultinomialNB(),\n",
    "             naive_bayes.BernoulliNB())\n",
    "nb_models = (model.fit(X_train_minmax, y_train) for model in nb_models)\n",
    "\n",
    "print('Number of mislabeled points out of test set of %d points:' % (X_test.shape[0]))\n",
    "\n",
    "for model, title in zip(nb_models, nb_titles):\n",
    "    y_pred = model.predict(X_test_minmax)\n",
    "    wrong = (y_test != y_pred).sum()\n",
    "    score = model.score(X_test_minmax, y_test)\n",
    "    print('%s: %d (score: %.2f)' %(title, wrong, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "![svm](assets/classification/svm.png)\n",
    "\n",
    "(image: [Wikipedia](https://en.wikipedia.org/wiki/Support_vector_machine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "- Inputs: features (not necessarily independent)\n",
    "  - Features should be scaled\n",
    "- Output: classes, separated by \"hyperplane\"\n",
    "\n",
    "- SVM uses \"kernel functions\" to compute the similarity between input samples\n",
    "- Find hyperplane with the maximum margin of separation\n",
    "  - Why? Better generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Libraries\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "- Support Vector Classifier\n",
    "- Different kernel functions to choose from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Scikit-learn has a nifty example that shows how the different kernel functions look like.\n",
    "\n",
    "To illustrate them, we'll use their code example to train SVM models with only 2 features.\n",
    "- Why 2 features? Because it's easier to plot in 2-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/auto_examples/svm/plot_iris.html#sphx-glr-auto-examples-svm-plot-iris-py\n",
    "from sklearn import svm\n",
    "\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    \"\"\"Create a mesh of points to plot in\n",
    "\n",
    "    Args:\n",
    "        x: data to base x-axis meshgrid on\n",
    "        y: data to base y-axis meshgrid on\n",
    "        h: stepsize for meshgrid, optional\n",
    "\n",
    "    Returns:\n",
    "        xx, yy : ndarray\n",
    "    \"\"\"\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    \"\"\"Plot the decision boundaries for a classifier.\n",
    "\n",
    "    Args:\n",
    "        ax: matplotlib axes object\n",
    "        clf: a classifier\n",
    "        xx: meshgrid ndarray\n",
    "        yy: meshgrid ndarray\n",
    "        params: dictionary of params to pass to contourf, optional\n",
    "    \"\"\"\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "fig, sub = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "# Take the first two features. We could avoid this by using a two-dim dataset\n",
    "X_train_svc = X_train[:, :2]\n",
    "\n",
    "# LinearSVC uses liblinear, SVC uses libsvm\n",
    "# Both are different implementations of SVM\n",
    "svm_titles = ['LinearSVC (liblinear)',\n",
    "              'SVC (linear kernel)',\n",
    "              'SVC (RBF kernel)',\n",
    "              'SVC (3-degree polynomial kernel)']\n",
    "\n",
    "# we create an instance of SVM and fit our data. We do not scale our\n",
    "# data since we want to plot the support vectors\n",
    "C = 1.0  # SVM regularization parameter\n",
    "svm_2D_models = (svm.SVC(kernel='linear', C=C),\n",
    "          svm.LinearSVC(C=C),\n",
    "          svm.SVC(kernel='rbf', gamma=0.7, C=C),\n",
    "          svm.SVC(kernel='poly', degree=3, C=C))\n",
    "svm_2D_models = (clf.fit(X_train_svc, y_train) for clf in svm_2D_models)\n",
    "\n",
    "X0, X1 = X_train_svc[:, 0], X_train_svc[:, 1]\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "for clf, title, ax in zip(svm_2D_models, svm_titles, sub.flatten()):\n",
    "    plot_contours(ax, clf, xx, yy,\n",
    "                  cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    ax.scatter(X0, X1, c=y_train, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xlabel('Sepal length')\n",
    "    ax.set_ylabel('Sepal width')\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Let's compare the performance of SVM with the other Classification models (Logistic Regression, Naive Bayes)\n",
    "\n",
    "To do that, we retrain the SVM models with the full features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Exercise - Train and score SVM using different kernels\n",
    "\n",
    "Train SVM models for the 4 kernel functions.\n",
    "\n",
    "For each model:\n",
    "- Scale X_train and X_test using sklearn.preprocessing.StandardScaler.\n",
    "  - X_train and X_test are multi-dimensional numpy arrays, so you can pass them directly into the scaler without reshaping.\n",
    "- Print the number of mislabeled points\n",
    "- Print the score\n",
    "\n",
    "Use all the features instead of just the first two.\n",
    "\n",
    "Which model performs the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-nearest Neighbors\n",
    "\n",
    "K-nearest neighbors is a multi-purpose algorithm that can be used for multi-class classification.\n",
    "\n",
    "- Find K closest neighbors to that sample\n",
    "- Classify by majority vote of the classes of that sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![knn](assets/classification/knn.png)\n",
    "\n",
    "(image: [dataaspirant.com](http://dataaspirant.com/2016/12/30/k-nearest-neighbor-implementation-scikit-learn/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Libraries\n",
    "\n",
    "sklearn.neighbors.KNeighborsClassifier\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "# K (how many neighbors to consider for the vote)\n",
    "n_neighbors = [3, 5, 15]\n",
    "\n",
    "# types of weights\n",
    "weights = ['uniform', 'distance']\n",
    "\n",
    "kn_models = []\n",
    "\n",
    "for k in n_neighbors:\n",
    "    for weight in weights:\n",
    "        model = neighbors.KNeighborsClassifier(k, weights=weight)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        wrong = (y_test != y_pred).sum()\n",
    "        score = model.score(X_test, y_test)\n",
    "        print('k = %d, weights = %s: %d (score: %.2f)' %(k, weight, wrong, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "X_train_plot = X_train[:, :2]\n",
    "h = .02  # step size in the mesh\n",
    "n_neighbors = 15\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "for weights in ['uniform', 'distance']:\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)\n",
    "    clf.fit(X_train_plot, y_train)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    x_min, x_max = X_train_plot[:, 0].min() - 1, X_plot[:, 0].max() + 1\n",
    "    y_min, y_max = X_train_plot[:, 1].min() - 1, X_plot[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X_train_plot[:, 0], X_train_plot[:, 1], c=y_train, cmap=cmap_bold,\n",
    "                edgecolor='k', s=20)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(\"3-Class classification (k = %i, weights = '%s')\"\n",
    "              % (n_neighbors, weights))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Quick Comparison\n",
    "\n",
    "|Criteria|Logistic Regression|Naive Bayes|SVM|K-nearest neighbors|\n",
    "|--|--|--|--|--|\n",
    "|Interpretability|Simple|Very simple (Conditional Probabilities)|Hard to understand parameters|Simple, but need to pick K|\n",
    "|Ease of training|Fast to train|Fast to train|Computationally and memory intensive for high dimensional data|Can be expensive for high dimensional data|\n",
    "|Requires independent features|Yes, but may still work|Yes, assumes independence|No (don't care)|No (don't care)|\n",
    "|Feature value ranges|No requirements, scale if vary too widely|No negative features|Must scale to [-1, 1]|No requirements|\n",
    "|Output usefulness|Returns probabilities and categories|Returns probabilities and categories|Returns probabilities and categories|Returns probabilities and categories|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Evaluation Metrics for Classification Problems\n",
    "\n",
    "- Confusion matrix\n",
    "- Accuracy\n",
    "- Precision, Recall, F1 score, ...\n",
    "- Area Under Curve\n",
    "\n",
    "Baselines: Random guess, Majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "|Truth/Prediction|Predicted Happy|Predicted Sad|\n",
    "|--|--|--|\n",
    "|Actually Happy|**True positive count**|*False negative count*|\n",
    "|Actually Sad|*False positive count*|**True negative count**|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "|Truth/Prediction|Predicted Happy|Predicted Sad|\n",
    "|--|--|--|\n",
    "|Actually Happy|**4**|*3*|\n",
    "|Actually Sad|*2*|**1**|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Accuracy\n",
    "\n",
    "$$accuracy(y\\_true, y\\_pred) = \\frac{true\\_positives + true\\_negatives}{total}$$\n",
    "\n",
    "What's the accuracy in our example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precision\n",
    "\n",
    "$$precision(y\\_true, y\\_pred) = \\frac{true\\_positives}{true\\_positives + false\\_positives}$$ \n",
    "\n",
    "What's the precision in our example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall (True Positive Rate / Sensitivity)\n",
    "\n",
    "$$recall(y\\_true, y\\_pred) = \\frac{true\\_positives}{true\\_positives + false\\_negatives}$$ \n",
    "\n",
    "What's the recall in our example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Specificity (1 - True Negative Rate)\n",
    "\n",
    "$$specificity(y\\_true, y\\_pred) = \\frac{true\\_negatives}{true\\_negatives + false\\_positives}$$\n",
    "\n",
    "What's the specificity in our example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### F1 score / F measure\n",
    "\n",
    "$$F(y\\_true, y\\_pred) = 2 * \\frac{precision * recall}{precision + recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What do they mean?\n",
    "\n",
    "<img src='assets/classification/precisionrecall.svg.png' width=60%/>\n",
    "\n",
    "(image: [Wikipedia](https://en.wikipedia.org/wiki/Precision_and_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Libraries\n",
    "\n",
    "http://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics\n",
    "- classification_report\n",
    "- confusion_matrix\n",
    "- accuracy_score\n",
    "- f1_score\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print('Logistic Regression:')\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_lr)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Colormaps:\n",
    "# https://matplotlib.org/gallery/color/colormap_reference.html\n",
    "plt.matshow(cm, cmap='Blues')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "iris.target_names # the integer values [0, 1, 2] map to these labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Exercise - Evaluation Metrics for Naive Bayes and SVM Classifiers\n",
    "\n",
    "For the Naive Bayes and SVM models we've seen so far:\n",
    "1. Get the classification metrics.\n",
    "2. Plot the confusion matrix\n",
    "3. How would you interpret the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Get the classification metrics\n",
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the confusion matrices for Naive Bayes\n",
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the confusion matrices for SVM\n",
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Area under ROC curve\n",
    "\n",
    "ROC curve: Receiver Operating Characteristic\n",
    "\n",
    "A plot of True Positive Rate (Recall) vs. False Positive Rate (1-Specificity)\n",
    "\n",
    "Larger area under ROC curve: better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Area under ROC curve\n",
    "\n",
    "![roc](assets/classification/sphx_glr_plot_roc_crossval_001.png)\n",
    "\n",
    "(image: [scikit-learn](http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Libraries\n",
    "\n",
    "sklearn.metrics.roc_curve: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html\n",
    "\n",
    "sklearn.metrics.auc: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ROC curves and Multi-class Classification\n",
    "\n",
    "- ROC is typically for binary classification\n",
    "- To plot ROC for multi-class:\n",
    "  - Either draw 1 curve per class\n",
    "  - Or compute average for all the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "\n",
    "# binarize the y labels\n",
    "y = label_binarize(iris.target, classes=[0, 1, 2])\n",
    "\n",
    "n_classes = y.shape[1]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Add noisy features to make the problem harder\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# Shuffle and split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
    "                                                    random_state=42)\n",
    "\n",
    "classifier = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and AROC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the ROC curves\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "for i in range(n_classes):\n",
    "    ax.plot(fpr[i], tpr[i], label='ROC curve of class %d (area = %0.2f)' % (i, roc_auc[i]))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "livereveal": {
   "autolaunch": false,
   "overlay": "<div class='logo'><img src='assets/Stackup_Logo_Small.png' width='90%'/></div>"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
